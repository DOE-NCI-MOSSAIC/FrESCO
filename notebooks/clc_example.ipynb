{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7424773b",
   "metadata": {},
   "source": [
    "This is an example for running the FrESCO library with a hierarchical version of the P3B3 becnhmark data from the ECP-Candle [repository](https://github.com/ECP-CANDLE/Benchmarks) with an added key `groups` which deginates how different entries are grouped together. Included within the FrESCO repository is a preformatted version of the clc dataset for model training. If you've not already done so, go to the data directory and unzip the dataset using the command `$ tar -xf clc.tar.gz`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460646d6",
   "metadata": {},
   "source": [
    "Training a case-level context (clc) model is a two step process. Initially we'll need to train a model on the data. We can do this in a similar fashion to the other datasets. In the `configs/` directory are sample `model_args.yml` files for the three sample datasets; we've supplied a sample `clc_step1.yml` configuration file. Using the default settings in this files, we are ready to train a model for the first step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73c2a2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fresco\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa26c90",
   "metadata": {},
   "source": [
    "The FrESCO library is typically run from the command line with arguments specifying the model type and model args, so we'll have to set them up manually for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5913468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    _ = parser.add_argument(\"--model\", \"-m\", type=str, default='ie',\n",
    "                        help=\"\"\"which type of model to create. Must be either\n",
    "                                IE (information extraction) or clc (case-level context).\"\"\")\n",
    "    _ = parser.add_argument('--model_path', '-mp', type=str, default='',\n",
    "                       help=\"\"\"this is the location of the model\n",
    "                               that will used to make predictions\"\"\")\n",
    "    _ = parser.add_argument('--data_path', '-dp', type=str, default='',\n",
    "                        help=\"\"\"where the data will load from. The default is\n",
    "                                the path saved in the model\"\"\")\n",
    "    _ = parser.add_argument('--model_args', '-args', type=str, default='',\n",
    "                        help=\"\"\"file specifying the model or clc args; default is in\n",
    "                                the fresco directory\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e7fe4b",
   "metadata": {},
   "source": [
    "We are going to train a multi-task classification model on the clc dataset, the first step of which is an `information extraction` model. We'll also point the code to the step 1 clc model args file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85e7eddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(args=['-m', 'ie', '-args', '../configs/clc_step1.yml'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1504aa2",
   "metadata": {},
   "source": [
    "With these arguments specified, just need a few imports before we're ready to train our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91cc5acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fresco import run_ie, run_clc\n",
    "\n",
    "from fresco.validate import exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a9fb57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating kwargs in model_args.yml file\n",
      "Word embeddings file does not exist; will default to random embeddings.\n",
      "Loading data and creating DataLoaders\n",
      "Loading data from ../data/clc/\n",
      "Num workers: 4, reproducible: True\n",
      "Training on 15000 validate on 2000\n",
      "\n",
      "Defining a model\n",
      "Creating model trainer\n",
      "Training a mthisan model with 2 cuda device\n",
      "\n",
      "\n",
      "epoch: 1\n",
      "\n",
      "training time 18.49\n",
      "Training loss: 0.850133\n",
      "        task:      micro        macro\n",
      "      task_1:     0.5279,     0.0543\n",
      "      task_2:     0.5434,     0.4547\n",
      "      task_3:     0.8853,     0.4831\n",
      "      task_4:     0.4539,     0.3080\n",
      "\n",
      "epoch 1 validation\n",
      "\n",
      "epoch 1 val loss: 1.09322788, best val loss: inf\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.5440,     0.0902\n",
      "      task_2:     0.5920,     0.4501\n",
      "      task_3:     0.8860,     0.4698\n",
      "      task_4:     0.4900,     0.3412\n",
      "\n",
      "epoch: 2\n",
      "\n",
      "training time 17.48\n",
      "Training loss: 0.884933\n",
      "        task:      micro        macro\n",
      "      task_1:     0.5459,     0.1192\n",
      "      task_2:     0.5409,     0.4760\n",
      "      task_3:     0.8935,     0.4719\n",
      "      task_4:     0.4493,     0.3103\n",
      "\n",
      "epoch 2 validation\n",
      "\n",
      "epoch 2 val loss: 0.98785399, best val loss: 1.09322788\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.5440,     0.0902\n",
      "      task_2:     0.5940,     0.4354\n",
      "      task_3:     0.8860,     0.4698\n",
      "      task_4:     0.4470,     0.2625\n",
      "\n",
      "epoch: 3\n",
      "\n",
      "training time 17.83\n",
      "Training loss: 0.852572\n",
      "        task:      micro        macro\n",
      "      task_1:     0.5470,     0.1195\n",
      "      task_2:     0.5453,     0.4768\n",
      "      task_3:     0.8935,     0.4719\n",
      "      task_4:     0.4519,     0.3126\n",
      "\n",
      "epoch 3 validation\n",
      "\n",
      "epoch 3 val loss: 0.91741740, best val loss: 0.98785399\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.5450,     0.1228\n",
      "      task_2:     0.6100,     0.4670\n",
      "      task_3:     0.8880,     0.4703\n",
      "      task_4:     0.4470,     0.2591\n",
      "\n",
      "epoch: 4\n",
      "\n",
      "training time 17.98\n",
      "Training loss: 0.799363\n",
      "        task:      micro        macro\n",
      "      task_1:     0.5485,     0.1209\n",
      "      task_2:     0.5865,     0.5262\n",
      "      task_3:     0.8935,     0.4719\n",
      "      task_4:     0.4607,     0.3164\n",
      "\n",
      "epoch 4 validation\n",
      "\n",
      "epoch 4 val loss: 0.82082257, best val loss: 0.91741740\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.5720,     0.1594\n",
      "      task_2:     0.8300,     0.8139\n",
      "      task_3:     0.8890,     0.4794\n",
      "      task_4:     0.4590,     0.2769\n",
      "\n",
      "epoch: 5\n",
      "\n",
      "training time 18.10\n",
      "Training loss: 0.651940\n",
      "        task:      micro        macro\n",
      "      task_1:     0.5692,     0.1570\n",
      "      task_2:     0.8883,     0.8838\n",
      "      task_3:     0.8933,     0.4718\n",
      "      task_4:     0.4630,     0.3226\n",
      "\n",
      "epoch 5 validation\n",
      "\n",
      "epoch 5 val loss: 0.66945520, best val loss: 0.82082257\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.7540,     0.2802\n",
      "      task_2:     0.9170,     0.9130\n",
      "      task_3:     0.8880,     0.4875\n",
      "      task_4:     0.5160,     0.3993\n",
      "\n",
      "epoch: 6\n",
      "\n",
      "training time 18.20\n",
      "Training loss: 0.557755\n",
      "        task:      micro        macro\n",
      "      task_1:     0.6814,     0.2467\n",
      "      task_2:     0.8969,     0.8932\n",
      "      task_3:     0.8933,     0.4737\n",
      "      task_4:     0.4945,     0.3744\n",
      "\n",
      "epoch 6 validation\n",
      "\n",
      "epoch 6 val loss: 0.59180538, best val loss: 0.66945520\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.7590,     0.2779\n",
      "      task_2:     0.9180,     0.9143\n",
      "      task_3:     0.8740,     0.5720\n",
      "      task_4:     0.5480,     0.5073\n",
      "\n",
      "epoch: 7\n",
      "\n",
      "training time 18.19\n",
      "Training loss: 0.513290\n",
      "        task:      micro        macro\n",
      "      task_1:     0.7313,     0.2915\n",
      "      task_2:     0.9011,     0.8980\n",
      "      task_3:     0.8931,     0.4845\n",
      "      task_4:     0.5388,     0.4513\n",
      "\n",
      "epoch 7 validation\n",
      "\n",
      "epoch 7 val loss: 0.54839981, best val loss: 0.59180538\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.7570,     0.2772\n",
      "      task_2:     0.9140,     0.9102\n",
      "      task_3:     0.8840,     0.7349\n",
      "      task_4:     0.5690,     0.5362\n",
      "\n",
      "epoch: 8\n",
      "\n",
      "training time 18.23\n",
      "Training loss: 0.504235\n",
      "        task:      micro        macro\n",
      "      task_1:     0.7462,     0.3399\n",
      "      task_2:     0.9041,     0.9012\n",
      "      task_3:     0.8958,     0.5240\n",
      "      task_4:     0.5693,     0.4896\n",
      "\n",
      "epoch 8 validation\n",
      "\n",
      "epoch 8 val loss: 0.50787422, best val loss: 0.54839981\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.7650,     0.2855\n",
      "      task_2:     0.9190,     0.9153\n",
      "      task_3:     0.9170,     0.8056\n",
      "      task_4:     0.5950,     0.5755\n",
      "\n",
      "epoch: 9\n",
      "\n",
      "training time 18.23\n",
      "Training loss: 0.449532\n",
      "        task:      micro        macro\n",
      "      task_1:     0.7663,     0.4064\n",
      "      task_2:     0.9077,     0.9048\n",
      "      task_3:     0.9075,     0.6179\n",
      "      task_4:     0.5913,     0.5169\n",
      "\n",
      "epoch 9 validation\n",
      "\n",
      "epoch 9 val loss: 0.48629755, best val loss: 0.50787422\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.7700,     0.3018\n",
      "      task_2:     0.9140,     0.9102\n",
      "      task_3:     0.9160,     0.8213\n",
      "      task_4:     0.5850,     0.5672\n",
      "\n",
      "epoch: 10\n",
      "\n",
      "training time 18.25\n",
      "Training loss: 0.428919\n",
      "        task:      micro        macro\n",
      "      task_1:     0.7814,     0.4612\n",
      "      task_2:     0.9105,     0.9076\n",
      "      task_3:     0.9290,     0.7537\n",
      "      task_4:     0.6087,     0.5430\n",
      "\n",
      "epoch 10 validation\n",
      "\n",
      "epoch 10 val loss: 0.46231049, best val loss: 0.48629755\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.7790,     0.3602\n",
      "      task_2:     0.9130,     0.9091\n",
      "      task_3:     0.9200,     0.8319\n",
      "      task_4:     0.6180,     0.5961\n",
      "\n",
      "epoch: 11\n",
      "\n",
      "training time 18.27\n",
      "Training loss: 0.379750\n",
      "        task:      micro        macro\n",
      "      task_1:     0.7982,     0.5224\n",
      "      task_2:     0.9133,     0.9107\n",
      "      task_3:     0.9445,     0.8253\n",
      "      task_4:     0.6297,     0.5726\n",
      "\n",
      "epoch 11 validation\n",
      "\n",
      "epoch 11 val loss: 0.43385451, best val loss: 0.46231049\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.8000,     0.4502\n",
      "      task_2:     0.9210,     0.9178\n",
      "      task_3:     0.9300,     0.8492\n",
      "      task_4:     0.6440,     0.6275\n",
      "\n",
      "epoch: 12\n",
      "\n",
      "training time 18.27\n",
      "Training loss: 0.347033\n",
      "        task:      micro        macro\n",
      "      task_1:     0.8153,     0.5841\n",
      "      task_2:     0.9151,     0.9125\n",
      "      task_3:     0.9549,     0.8659\n",
      "      task_4:     0.6545,     0.6079\n",
      "\n",
      "epoch 12 validation\n",
      "\n",
      "epoch 12 val loss: 0.41187937, best val loss: 0.43385451\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.8130,     0.5163\n",
      "      task_2:     0.9230,     0.9200\n",
      "      task_3:     0.9360,     0.8595\n",
      "      task_4:     0.6700,     0.6564\n",
      "\n",
      "epoch: 13\n",
      "\n",
      "training time 18.28\n",
      "Training loss: 0.313501\n",
      "        task:      micro        macro\n",
      "      task_1:     0.8359,     0.6502\n",
      "      task_2:     0.9177,     0.9153\n",
      "      task_3:     0.9615,     0.8875\n",
      "      task_4:     0.6820,     0.6405\n",
      "\n",
      "epoch 13 validation\n",
      "\n",
      "epoch 13 val loss: 0.39211367, best val loss: 0.41187937\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.8280,     0.5788\n",
      "      task_2:     0.9240,     0.9212\n",
      "      task_3:     0.9420,     0.8718\n",
      "      task_4:     0.6950,     0.6813\n",
      "\n",
      "epoch: 14\n",
      "\n",
      "training time 18.30\n",
      "Training loss: 0.320911\n",
      "        task:      micro        macro\n",
      "      task_1:     0.8537,     0.7005\n",
      "      task_2:     0.9167,     0.9142\n",
      "      task_3:     0.9645,     0.8982\n",
      "      task_4:     0.7029,     0.6663\n",
      "\n",
      "epoch 14 validation\n",
      "\n",
      "epoch 14 val loss: 0.36886978, best val loss: 0.39211367\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.8390,     0.6272\n",
      "      task_2:     0.9330,     0.9307\n",
      "      task_3:     0.9460,     0.8790\n",
      "      task_4:     0.7360,     0.7227\n",
      "\n",
      "epoch: 15\n",
      "\n",
      "training time 18.34\n",
      "Training loss: 0.263041\n",
      "        task:      micro        macro\n",
      "      task_1:     0.8683,     0.7375\n",
      "      task_2:     0.9196,     0.9172\n",
      "      task_3:     0.9675,     0.9080\n",
      "      task_4:     0.7352,     0.7022\n",
      "\n",
      "epoch 15 validation\n",
      "\n",
      "epoch 15 val loss: 0.35353596, best val loss: 0.36886978\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.8550,     0.6720\n",
      "      task_2:     0.9320,     0.9296\n",
      "      task_3:     0.9490,     0.8869\n",
      "      task_4:     0.7600,     0.7474\n",
      "\n",
      "epoch: 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training time 18.36\n",
      "Training loss: 0.255799\n",
      "        task:      micro        macro\n",
      "      task_1:     0.8809,     0.7684\n",
      "      task_2:     0.9216,     0.9194\n",
      "      task_3:     0.9673,     0.9077\n",
      "      task_4:     0.7516,     0.7189\n",
      "\n",
      "epoch 16 validation\n",
      "\n",
      "epoch 16 val loss: 0.34222861, best val loss: 0.35353596\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.8720,     0.7215\n",
      "      task_2:     0.9370,     0.9349\n",
      "      task_3:     0.9480,     0.8851\n",
      "      task_4:     0.7710,     0.7616\n",
      "\n",
      "epoch: 17\n",
      "\n",
      "training time 18.38\n",
      "Training loss: 0.198007\n",
      "        task:      micro        macro\n",
      "      task_1:     0.8917,     0.7940\n",
      "      task_2:     0.9231,     0.9211\n",
      "      task_3:     0.9717,     0.9210\n",
      "      task_4:     0.7785,     0.7493\n",
      "\n",
      "epoch 17 validation\n",
      "\n",
      "epoch 17 val loss: 0.33303011, best val loss: 0.34222861\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.8760,     0.7360\n",
      "      task_2:     0.9350,     0.9329\n",
      "      task_3:     0.9520,     0.8946\n",
      "      task_4:     0.7910,     0.7783\n",
      "\n",
      "epoch: 18\n",
      "\n",
      "training time 18.35\n",
      "Training loss: 0.171668\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9041,     0.8208\n",
      "      task_2:     0.9238,     0.9218\n",
      "      task_3:     0.9713,     0.9210\n",
      "      task_4:     0.8007,     0.7762\n",
      "\n",
      "epoch 18 validation\n",
      "\n",
      "epoch 18 val loss: 0.32028950, best val loss: 0.33303011\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.8890,     0.7688\n",
      "      task_2:     0.9380,     0.9361\n",
      "      task_3:     0.9510,     0.8906\n",
      "      task_4:     0.8060,     0.7922\n",
      "\n",
      "epoch: 19\n",
      "\n",
      "training time 18.29\n",
      "Training loss: 0.176734\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9085,     0.8303\n",
      "      task_2:     0.9249,     0.9229\n",
      "      task_3:     0.9749,     0.9306\n",
      "      task_4:     0.8187,     0.7974\n",
      "\n",
      "epoch 19 validation\n",
      "\n",
      "epoch 19 val loss: 0.31421283, best val loss: 0.32028950\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9010,     0.8039\n",
      "      task_2:     0.9360,     0.9340\n",
      "      task_3:     0.9550,     0.9002\n",
      "      task_4:     0.8270,     0.8142\n",
      "\n",
      "epoch: 20\n",
      "\n",
      "training time 18.31\n",
      "Training loss: 0.133424\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9140,     0.8426\n",
      "      task_2:     0.9275,     0.9257\n",
      "      task_3:     0.9753,     0.9319\n",
      "      task_4:     0.8314,     0.8107\n",
      "\n",
      "epoch 20 validation\n",
      "\n",
      "epoch 20 val loss: 0.30419402, best val loss: 0.31421283\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9090,     0.8261\n",
      "      task_2:     0.9320,     0.9299\n",
      "      task_3:     0.9550,     0.8982\n",
      "      task_4:     0.8330,     0.8211\n",
      "\n",
      "epoch: 21\n",
      "\n",
      "training time 18.33\n",
      "Training loss: 0.142395\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9224,     0.8608\n",
      "      task_2:     0.9283,     0.9265\n",
      "      task_3:     0.9783,     0.9403\n",
      "      task_4:     0.8490,     0.8303\n",
      "\n",
      "epoch 21 validation\n",
      "\n",
      "epoch 21 val loss: 0.29906543, best val loss: 0.30419402\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9190,     0.8517\n",
      "      task_2:     0.9320,     0.9299\n",
      "      task_3:     0.9550,     0.8995\n",
      "      task_4:     0.8460,     0.8352\n",
      "\n",
      "epoch: 22\n",
      "\n",
      "training time 18.35\n",
      "Training loss: 0.106238\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9268,     0.8703\n",
      "      task_2:     0.9291,     0.9274\n",
      "      task_3:     0.9798,     0.9446\n",
      "      task_4:     0.8598,     0.8426\n",
      "\n",
      "epoch 22 validation\n",
      "\n",
      "epoch 22 val loss: 0.29301407, best val loss: 0.29906543\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9200,     0.8543\n",
      "      task_2:     0.9350,     0.9330\n",
      "      task_3:     0.9570,     0.9027\n",
      "      task_4:     0.8560,     0.8449\n",
      "\n",
      "epoch: 23\n",
      "\n",
      "training time 18.35\n",
      "Training loss: 0.108621\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9323,     0.8796\n",
      "      task_2:     0.9299,     0.9282\n",
      "      task_3:     0.9805,     0.9469\n",
      "      task_4:     0.8715,     0.8532\n",
      "\n",
      "epoch 23 validation\n",
      "\n",
      "epoch 23 val loss: 0.29010916, best val loss: 0.29301407\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9250,     0.8656\n",
      "      task_2:     0.9340,     0.9320\n",
      "      task_3:     0.9600,     0.9098\n",
      "      task_4:     0.8680,     0.8590\n",
      "\n",
      "epoch: 24\n",
      "\n",
      "training time 18.30\n",
      "Training loss: 0.073651\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9362,     0.8890\n",
      "      task_2:     0.9314,     0.9297\n",
      "      task_3:     0.9819,     0.9507\n",
      "      task_4:     0.8823,     0.8678\n",
      "\n",
      "epoch 24 validation\n",
      "\n",
      "epoch 24 val loss: 0.28750569, best val loss: 0.29010916\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9300,     0.8763\n",
      "      task_2:     0.9360,     0.9340\n",
      "      task_3:     0.9640,     0.9177\n",
      "      task_4:     0.8750,     0.8661\n",
      "\n",
      "epoch: 25\n",
      "\n",
      "training time 18.30\n",
      "Training loss: 0.069602\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9380,     0.8934\n",
      "      task_2:     0.9338,     0.9322\n",
      "      task_3:     0.9829,     0.9537\n",
      "      task_4:     0.8911,     0.8762\n",
      "\n",
      "epoch 25 validation\n",
      "\n",
      "epoch 25 val loss: 0.28641164, best val loss: 0.28750569\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9300,     0.8766\n",
      "      task_2:     0.9340,     0.9319\n",
      "      task_3:     0.9640,     0.9183\n",
      "      task_4:     0.8810,     0.8720\n",
      "\n",
      "epoch: 26\n",
      "\n",
      "training time 18.31\n",
      "Training loss: 0.065795\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9409,     0.8970\n",
      "      task_2:     0.9373,     0.9359\n",
      "      task_3:     0.9827,     0.9533\n",
      "      task_4:     0.8961,     0.8839\n",
      "\n",
      "epoch 26 validation\n",
      "\n",
      "epoch 26 val loss: 0.28686405, best val loss: 0.28641164\n",
      "patience counter is at 1 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9330,     0.8812\n",
      "      task_2:     0.9380,     0.9361\n",
      "      task_3:     0.9660,     0.9228\n",
      "      task_4:     0.8880,     0.8778\n",
      "\n",
      "epoch: 27\n",
      "\n",
      "training time 18.35\n",
      "Training loss: 0.068524\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9445,     0.9038\n",
      "      task_2:     0.9367,     0.9353\n",
      "      task_3:     0.9845,     0.9581\n",
      "      task_4:     0.9037,     0.8910\n",
      "\n",
      "epoch 27 validation\n",
      "\n",
      "epoch 27 val loss: 0.28894620, best val loss: 0.28641164\n",
      "patience counter is at 2 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9340,     0.8841\n",
      "      task_2:     0.9370,     0.9351\n",
      "      task_3:     0.9640,     0.9188\n",
      "      task_4:     0.8900,     0.8813\n",
      "\n",
      "epoch: 28\n",
      "\n",
      "training time 18.34\n",
      "Training loss: 0.065721\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9485,     0.9131\n",
      "      task_2:     0.9374,     0.9360\n",
      "      task_3:     0.9859,     0.9618\n",
      "      task_4:     0.9099,     0.8980\n",
      "\n",
      "epoch 28 validation\n",
      "\n",
      "epoch 28 val loss: 0.28821320, best val loss: 0.28641164\n",
      "patience counter is at 3 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9380,     0.8889\n",
      "      task_2:     0.9400,     0.9382\n",
      "      task_3:     0.9690,     0.9289\n",
      "      task_4:     0.8880,     0.8780\n",
      "\n",
      "epoch: 29\n",
      "\n",
      "training time 18.29\n",
      "Training loss: 0.052091\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9521,     0.9172\n",
      "      task_2:     0.9385,     0.9371\n",
      "      task_3:     0.9869,     0.9647\n",
      "      task_4:     0.9152,     0.9049\n",
      "\n",
      "epoch 29 validation\n",
      "\n",
      "epoch 29 val loss: 0.28809249, best val loss: 0.28641164\n",
      "patience counter is at 4 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9380,     0.8916\n",
      "      task_2:     0.9410,     0.9392\n",
      "      task_3:     0.9690,     0.9289\n",
      "      task_4:     0.8990,     0.8896\n",
      "\n",
      "epoch: 30\n",
      "\n",
      "training time 18.31\n",
      "Training loss: 0.038519\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9526,     0.9169\n",
      "      task_2:     0.9443,     0.9430\n",
      "      task_3:     0.9871,     0.9653\n",
      "      task_4:     0.9226,     0.9118\n",
      "\n",
      "epoch 30 validation\n",
      "\n",
      "epoch 30 val loss: 0.28827911, best val loss: 0.28641164\n",
      "patience counter is at 5 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9390,     0.8942\n",
      "      task_2:     0.9420,     0.9402\n",
      "      task_3:     0.9700,     0.9310\n",
      "      task_4:     0.8980,     0.8867\n",
      "saving to savedmodels/clc_model/clc_model_fold0.h5\n",
      "\n",
      "Scoring test set\n",
      "\n",
      "Predicting train set\n",
      "\n",
      "Predicting val set\n",
      "\n",
      "Predicting test set\n",
      "Saving predictions to csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating train set\n",
      "\n",
      "Evaluating val set\n",
      "\n",
      "Evaluating test set\n",
      "Saving predictions to csv\n",
      "\n",
      "Full model file has been saved at savedmodels/clc_model/clc_model_20230816094757_fold0.h5\n"
     ]
    }
   ],
   "source": [
    "run_ie.run_ie(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e548e0",
   "metadata": {},
   "source": [
    "Now that we've trained an inital model, we're ready to train the final clc model. First we'll rename the saved model from step one, which is saved in `savedmodels` folder in the `scripts` directory. We will then specify the updated name in the args for step two; the default name for step two is `clc_model.h5`.  Having done this, we're on our way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93164fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(args=['-m', 'clc', '-args', '../configs/clc_step2.yml'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ecefce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating kwargs in clc_args.yml file\n",
      "Loading trained model from ./savedmodels/clc_model/clc_model.h5\n",
      "Word embeddings file does not exist; will default to random embeddings.\n",
      "Validating kwargs from pretrained model \n",
      "Word embeddings file does not exist; will default to random embeddings.\n",
      "Loading data and creating DataLoaders\n",
      "Loading data from ../data/clc/\n",
      "Num workers: 4, reproducible: True\n",
      "Training on 15000 validate on 2000\n",
      "model loaded\n",
      "\n",
      "Defining a CLC model\n",
      "Creating model trainer\n",
      "Training a case-level model with 2 cuda device\n",
      "\n",
      "\n",
      "epoch: 1\n",
      "\n",
      "training time 2.67\n",
      "Training loss: 0.340141\n",
      "        task:      micro        macro\n",
      "      task_1:     0.6537,     0.1548\n",
      "      task_2:     0.8583,     0.8555\n",
      "      task_3:     0.8933,     0.6348\n",
      "      task_4:     0.6447,     0.5967\n",
      "\n",
      "epoch 1 validation\n",
      "\n",
      "epoch 1 val loss: 0.31448648, best val loss: inf\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.8600,     0.6021\n",
      "      task_2:     0.9280,     0.9258\n",
      "      task_3:     0.9510,     0.8702\n",
      "      task_4:     0.8600,     0.8435\n",
      "\n",
      "epoch: 2\n",
      "\n",
      "training time 2.62\n",
      "Training loss: 0.254228\n",
      "        task:      micro        macro\n",
      "      task_1:     0.8771,     0.6090\n",
      "      task_2:     0.9326,     0.9312\n",
      "      task_3:     0.9559,     0.8770\n",
      "      task_4:     0.8485,     0.8196\n",
      "\n",
      "epoch 2 validation\n",
      "\n",
      "epoch 2 val loss: 0.24479401, best val loss: 0.31448648\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9080,     0.8081\n",
      "      task_2:     0.9330,     0.9307\n",
      "      task_3:     0.9730,     0.9334\n",
      "      task_4:     0.8760,     0.8648\n",
      "\n",
      "epoch: 3\n",
      "\n",
      "training time 2.56\n",
      "Training loss: 0.216166\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9174,     0.8322\n",
      "      task_2:     0.9363,     0.9350\n",
      "      task_3:     0.9713,     0.9236\n",
      "      task_4:     0.8773,     0.8557\n",
      "\n",
      "epoch 3 validation\n",
      "\n",
      "epoch 3 val loss: 0.22567702, best val loss: 0.24479401\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9140,     0.8277\n",
      "      task_2:     0.9320,     0.9297\n",
      "      task_3:     0.9770,     0.9437\n",
      "      task_4:     0.8820,     0.8714\n",
      "\n",
      "epoch: 4\n",
      "\n",
      "training time 2.58\n",
      "Training loss: 0.209563\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9318,     0.8710\n",
      "      task_2:     0.9371,     0.9359\n",
      "      task_3:     0.9778,     0.9415\n",
      "      task_4:     0.8889,     0.8722\n",
      "\n",
      "epoch 4 validation\n",
      "\n",
      "epoch 4 val loss: 0.21790028, best val loss: 0.22567702\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9280,     0.8665\n",
      "      task_2:     0.9330,     0.9307\n",
      "      task_3:     0.9770,     0.9437\n",
      "      task_4:     0.8860,     0.8767\n",
      "\n",
      "epoch: 5\n",
      "\n",
      "training time 2.62\n",
      "Training loss: 0.202177\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9359,     0.8810\n",
      "      task_2:     0.9384,     0.9372\n",
      "      task_3:     0.9791,     0.9448\n",
      "      task_4:     0.8939,     0.8793\n",
      "\n",
      "epoch 5 validation\n",
      "\n",
      "epoch 5 val loss: 0.21302289, best val loss: 0.21790028\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9330,     0.8766\n",
      "      task_2:     0.9340,     0.9318\n",
      "      task_3:     0.9770,     0.9437\n",
      "      task_4:     0.8910,     0.8826\n",
      "\n",
      "epoch: 6\n",
      "\n",
      "training time 2.64\n",
      "Training loss: 0.208125\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9399,     0.8897\n",
      "      task_2:     0.9396,     0.9384\n",
      "      task_3:     0.9791,     0.9451\n",
      "      task_4:     0.8951,     0.8802\n",
      "\n",
      "epoch 6 validation\n",
      "\n",
      "epoch 6 val loss: 0.20959379, best val loss: 0.21302289\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9360,     0.8833\n",
      "      task_2:     0.9340,     0.9318\n",
      "      task_3:     0.9750,     0.9384\n",
      "      task_4:     0.8890,     0.8794\n",
      "\n",
      "epoch: 7\n",
      "\n",
      "training time 2.64\n",
      "Training loss: 0.192289\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9437,     0.8994\n",
      "      task_2:     0.9373,     0.9360\n",
      "      task_3:     0.9817,     0.9518\n",
      "      task_4:     0.9008,     0.8873\n",
      "\n",
      "epoch 7 validation\n",
      "\n",
      "epoch 7 val loss: 0.20650422, best val loss: 0.20959379\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9380,     0.8884\n",
      "      task_2:     0.9350,     0.9329\n",
      "      task_3:     0.9760,     0.9410\n",
      "      task_4:     0.8910,     0.8803\n",
      "\n",
      "epoch: 8\n",
      "\n",
      "training time 2.64\n",
      "Training loss: 0.206076\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9434,     0.8981\n",
      "      task_2:     0.9399,     0.9387\n",
      "      task_3:     0.9821,     0.9530\n",
      "      task_4:     0.9034,     0.8919\n",
      "\n",
      "epoch 8 validation\n",
      "\n",
      "epoch 8 val loss: 0.20543506, best val loss: 0.20650422\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9370,     0.8858\n",
      "      task_2:     0.9320,     0.9297\n",
      "      task_3:     0.9760,     0.9410\n",
      "      task_4:     0.8910,     0.8799\n",
      "\n",
      "epoch: 9\n",
      "\n",
      "training time 2.65\n",
      "Training loss: 0.182155\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9453,     0.9024\n",
      "      task_2:     0.9416,     0.9404\n",
      "      task_3:     0.9838,     0.9573\n",
      "      task_4:     0.9033,     0.8915\n",
      "\n",
      "epoch 9 validation\n",
      "\n",
      "epoch 9 val loss: 0.20313109, best val loss: 0.20543506\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9380,     0.8883\n",
      "      task_2:     0.9350,     0.9329\n",
      "      task_3:     0.9770,     0.9433\n",
      "      task_4:     0.8910,     0.8803\n",
      "\n",
      "epoch: 10\n",
      "\n",
      "training time 2.65\n",
      "Training loss: 0.166874\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9474,     0.9062\n",
      "      task_2:     0.9413,     0.9402\n",
      "      task_3:     0.9839,     0.9575\n",
      "      task_4:     0.9065,     0.8955\n",
      "\n",
      "epoch 10 validation\n",
      "\n",
      "epoch 10 val loss: 0.20180273, best val loss: 0.20313109\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9360,     0.8834\n",
      "      task_2:     0.9340,     0.9318\n",
      "      task_3:     0.9790,     0.9486\n",
      "      task_4:     0.8910,     0.8809\n",
      "\n",
      "epoch: 11\n",
      "\n",
      "training time 2.67\n",
      "Training loss: 0.179883\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9492,     0.9100\n",
      "      task_2:     0.9423,     0.9411\n",
      "      task_3:     0.9833,     0.9560\n",
      "      task_4:     0.9041,     0.8930\n",
      "\n",
      "epoch 11 validation\n",
      "\n",
      "epoch 11 val loss: 0.19969858, best val loss: 0.20180273\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9360,     0.8848\n",
      "      task_2:     0.9340,     0.9319\n",
      "      task_3:     0.9780,     0.9455\n",
      "      task_4:     0.8910,     0.8797\n",
      "\n",
      "epoch: 12\n",
      "\n",
      "training time 2.65\n",
      "Training loss: 0.180400\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9493,     0.9102\n",
      "      task_2:     0.9423,     0.9412\n",
      "      task_3:     0.9848,     0.9598\n",
      "      task_4:     0.9069,     0.8955\n",
      "\n",
      "epoch 12 validation\n",
      "\n",
      "epoch 12 val loss: 0.19804112, best val loss: 0.19969858\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9370,     0.8868\n",
      "      task_2:     0.9350,     0.9329\n",
      "      task_3:     0.9780,     0.9460\n",
      "      task_4:     0.8920,     0.8830\n",
      "\n",
      "epoch: 13\n",
      "\n",
      "training time 2.64\n",
      "Training loss: 0.156362\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9493,     0.9097\n",
      "      task_2:     0.9426,     0.9415\n",
      "      task_3:     0.9845,     0.9590\n",
      "      task_4:     0.9069,     0.8969\n",
      "\n",
      "epoch 13 validation\n",
      "\n",
      "epoch 13 val loss: 0.19656948, best val loss: 0.19804112\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9390,     0.8916\n",
      "      task_2:     0.9320,     0.9298\n",
      "      task_3:     0.9780,     0.9460\n",
      "      task_4:     0.8900,     0.8792\n",
      "\n",
      "epoch: 14\n",
      "\n",
      "training time 2.67\n",
      "Training loss: 0.172499\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9486,     0.9100\n",
      "      task_2:     0.9451,     0.9440\n",
      "      task_3:     0.9853,     0.9614\n",
      "      task_4:     0.9073,     0.8966\n",
      "\n",
      "epoch 14 validation\n",
      "\n",
      "epoch 14 val loss: 0.19515529, best val loss: 0.19656948\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9380,     0.8886\n",
      "      task_2:     0.9330,     0.9307\n",
      "      task_3:     0.9790,     0.9482\n",
      "      task_4:     0.8930,     0.8844\n",
      "\n",
      "epoch: 15\n",
      "\n",
      "training time 2.68\n",
      "Training loss: 0.170334\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9515,     0.9149\n",
      "      task_2:     0.9458,     0.9447\n",
      "      task_3:     0.9852,     0.9609\n",
      "      task_4:     0.9087,     0.8976\n",
      "\n",
      "epoch 15 validation\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 val loss: 0.19408840, best val loss: 0.19515529\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9370,     0.8886\n",
      "      task_2:     0.9330,     0.9307\n",
      "      task_3:     0.9790,     0.9482\n",
      "      task_4:     0.8920,     0.8830\n",
      "\n",
      "epoch: 16\n",
      "\n",
      "training time 2.66\n",
      "Training loss: 0.175267\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9503,     0.9126\n",
      "      task_2:     0.9459,     0.9448\n",
      "      task_3:     0.9854,     0.9614\n",
      "      task_4:     0.9107,     0.9010\n",
      "\n",
      "epoch 16 validation\n",
      "\n",
      "epoch 16 val loss: 0.19336316, best val loss: 0.19408840\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9380,     0.8901\n",
      "      task_2:     0.9340,     0.9317\n",
      "      task_3:     0.9790,     0.9482\n",
      "      task_4:     0.8940,     0.8852\n",
      "\n",
      "epoch: 17\n",
      "\n",
      "training time 2.67\n",
      "Training loss: 0.166016\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9511,     0.9139\n",
      "      task_2:     0.9457,     0.9446\n",
      "      task_3:     0.9857,     0.9625\n",
      "      task_4:     0.9115,     0.9024\n",
      "\n",
      "epoch 17 validation\n",
      "\n",
      "epoch 17 val loss: 0.19185079, best val loss: 0.19336316\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9400,     0.8947\n",
      "      task_2:     0.9320,     0.9296\n",
      "      task_3:     0.9810,     0.9528\n",
      "      task_4:     0.8950,     0.8869\n",
      "\n",
      "epoch: 18\n",
      "\n",
      "training time 2.65\n",
      "Training loss: 0.147585\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9521,     0.9166\n",
      "      task_2:     0.9461,     0.9451\n",
      "      task_3:     0.9852,     0.9609\n",
      "      task_4:     0.9083,     0.8993\n",
      "\n",
      "epoch 18 validation\n",
      "\n",
      "epoch 18 val loss: 0.19146641, best val loss: 0.19185079\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9380,     0.8912\n",
      "      task_2:     0.9340,     0.9317\n",
      "      task_3:     0.9800,     0.9512\n",
      "      task_4:     0.8960,     0.8884\n",
      "\n",
      "epoch: 19\n",
      "\n",
      "training time 2.58\n",
      "Training loss: 0.156179\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9516,     0.9152\n",
      "      task_2:     0.9461,     0.9451\n",
      "      task_3:     0.9864,     0.9642\n",
      "      task_4:     0.9088,     0.9002\n",
      "\n",
      "epoch 19 validation\n",
      "\n",
      "epoch 19 val loss: 0.18977008, best val loss: 0.19146641\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9350,     0.8843\n",
      "      task_2:     0.9340,     0.9318\n",
      "      task_3:     0.9810,     0.9532\n",
      "      task_4:     0.8950,     0.8863\n",
      "\n",
      "epoch: 20\n",
      "\n",
      "training time 2.58\n",
      "Training loss: 0.160301\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9542,     0.9193\n",
      "      task_2:     0.9452,     0.9441\n",
      "      task_3:     0.9858,     0.9626\n",
      "      task_4:     0.9123,     0.9022\n",
      "\n",
      "epoch 20 validation\n",
      "\n",
      "epoch 20 val loss: 0.18851571, best val loss: 0.18977008\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9380,     0.8936\n",
      "      task_2:     0.9330,     0.9307\n",
      "      task_3:     0.9840,     0.9601\n",
      "      task_4:     0.8920,     0.8833\n",
      "\n",
      "epoch: 21\n",
      "\n",
      "training time 2.73\n",
      "Training loss: 0.145423\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9536,     0.9190\n",
      "      task_2:     0.9466,     0.9455\n",
      "      task_3:     0.9862,     0.9636\n",
      "      task_4:     0.9154,     0.9060\n",
      "\n",
      "epoch 21 validation\n",
      "\n",
      "epoch 21 val loss: 0.18785310, best val loss: 0.18851571\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9380,     0.8912\n",
      "      task_2:     0.9360,     0.9339\n",
      "      task_3:     0.9810,     0.9532\n",
      "      task_4:     0.8940,     0.8855\n",
      "\n",
      "epoch: 22\n",
      "\n",
      "training time 2.61\n",
      "Training loss: 0.155216\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9545,     0.9208\n",
      "      task_2:     0.9473,     0.9463\n",
      "      task_3:     0.9863,     0.9639\n",
      "      task_4:     0.9137,     0.9045\n",
      "\n",
      "epoch 22 validation\n",
      "\n",
      "epoch 22 val loss: 0.18695029, best val loss: 0.18785310\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9400,     0.8947\n",
      "      task_2:     0.9310,     0.9287\n",
      "      task_3:     0.9830,     0.9578\n",
      "      task_4:     0.8940,     0.8846\n",
      "\n",
      "epoch: 23\n",
      "\n",
      "training time 2.60\n",
      "Training loss: 0.135442\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9545,     0.9203\n",
      "      task_2:     0.9474,     0.9463\n",
      "      task_3:     0.9876,     0.9673\n",
      "      task_4:     0.9131,     0.9042\n",
      "\n",
      "epoch 23 validation\n",
      "\n",
      "epoch 23 val loss: 0.18590927, best val loss: 0.18695029\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9390,     0.8941\n",
      "      task_2:     0.9350,     0.9328\n",
      "      task_3:     0.9820,     0.9551\n",
      "      task_4:     0.8930,     0.8832\n",
      "\n",
      "epoch: 24\n",
      "\n",
      "training time 2.67\n",
      "Training loss: 0.151161\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9537,     0.9191\n",
      "      task_2:     0.9488,     0.9478\n",
      "      task_3:     0.9864,     0.9643\n",
      "      task_4:     0.9133,     0.9044\n",
      "\n",
      "epoch 24 validation\n",
      "\n",
      "epoch 24 val loss: 0.18523912, best val loss: 0.18590927\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9410,     0.8972\n",
      "      task_2:     0.9360,     0.9339\n",
      "      task_3:     0.9810,     0.9532\n",
      "      task_4:     0.8940,     0.8849\n",
      "\n",
      "epoch: 25\n",
      "\n",
      "training time 2.60\n",
      "Training loss: 0.126598\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9536,     0.9191\n",
      "      task_2:     0.9481,     0.9471\n",
      "      task_3:     0.9859,     0.9628\n",
      "      task_4:     0.9147,     0.9051\n",
      "\n",
      "epoch 25 validation\n",
      "\n",
      "epoch 25 val loss: 0.18450039, best val loss: 0.18523912\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9390,     0.8930\n",
      "      task_2:     0.9380,     0.9360\n",
      "      task_3:     0.9820,     0.9554\n",
      "      task_4:     0.8930,     0.8838\n",
      "\n",
      "epoch: 26\n",
      "\n",
      "training time 2.59\n",
      "Training loss: 0.142874\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9563,     0.9240\n",
      "      task_2:     0.9468,     0.9457\n",
      "      task_3:     0.9864,     0.9641\n",
      "      task_4:     0.9121,     0.9028\n",
      "\n",
      "epoch 26 validation\n",
      "\n",
      "epoch 26 val loss: 0.18388405, best val loss: 0.18450039\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9420,     0.9000\n",
      "      task_2:     0.9370,     0.9348\n",
      "      task_3:     0.9830,     0.9578\n",
      "      task_4:     0.8920,     0.8827\n",
      "\n",
      "epoch: 27\n",
      "\n",
      "training time 2.66\n",
      "Training loss: 0.140614\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9552,     0.9213\n",
      "      task_2:     0.9485,     0.9475\n",
      "      task_3:     0.9873,     0.9666\n",
      "      task_4:     0.9159,     0.9078\n",
      "\n",
      "epoch 27 validation\n",
      "\n",
      "epoch 27 val loss: 0.18314337, best val loss: 0.18388405\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9400,     0.8956\n",
      "      task_2:     0.9380,     0.9359\n",
      "      task_3:     0.9830,     0.9578\n",
      "      task_4:     0.8960,     0.8872\n",
      "\n",
      "epoch: 28\n",
      "\n",
      "training time 2.69\n",
      "Training loss: 0.128528\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9566,     0.9246\n",
      "      task_2:     0.9483,     0.9473\n",
      "      task_3:     0.9885,     0.9697\n",
      "      task_4:     0.9134,     0.9052\n",
      "\n",
      "epoch 28 validation\n",
      "\n",
      "epoch 28 val loss: 0.18211929, best val loss: 0.18314337\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9430,     0.9018\n",
      "      task_2:     0.9410,     0.9391\n",
      "      task_3:     0.9830,     0.9578\n",
      "      task_4:     0.8930,     0.8840\n",
      "\n",
      "epoch: 29\n",
      "\n",
      "training time 2.70\n",
      "Training loss: 0.145617\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9570,     0.9239\n",
      "      task_2:     0.9473,     0.9463\n",
      "      task_3:     0.9864,     0.9642\n",
      "      task_4:     0.9152,     0.9071\n",
      "\n",
      "epoch 29 validation\n",
      "\n",
      "epoch 29 val loss: 0.18210307, best val loss: 0.18211929\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9400,     0.8973\n",
      "      task_2:     0.9410,     0.9390\n",
      "      task_3:     0.9830,     0.9578\n",
      "      task_4:     0.8940,     0.8847\n",
      "\n",
      "epoch: 30\n",
      "\n",
      "training time 2.70\n",
      "Training loss: 0.142496\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9569,     0.9244\n",
      "      task_2:     0.9488,     0.9478\n",
      "      task_3:     0.9876,     0.9673\n",
      "      task_4:     0.9111,     0.9020\n",
      "\n",
      "epoch 30 validation\n",
      "\n",
      "epoch 30 val loss: 0.18106656, best val loss: 0.18210307\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9430,     0.9041\n",
      "      task_2:     0.9410,     0.9390\n",
      "      task_3:     0.9830,     0.9578\n",
      "      task_4:     0.8940,     0.8852\n",
      "\n",
      "epoch: 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training time 2.68\n",
      "Training loss: 0.145505\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9565,     0.9239\n",
      "      task_2:     0.9485,     0.9475\n",
      "      task_3:     0.9882,     0.9689\n",
      "      task_4:     0.9153,     0.9073\n",
      "\n",
      "epoch 31 validation\n",
      "\n",
      "epoch 31 val loss: 0.18084014, best val loss: 0.18106656\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9430,     0.9011\n",
      "      task_2:     0.9370,     0.9347\n",
      "      task_3:     0.9830,     0.9578\n",
      "      task_4:     0.8900,     0.8806\n",
      "\n",
      "epoch: 32\n",
      "\n",
      "training time 2.68\n",
      "Training loss: 0.142465\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9563,     0.9241\n",
      "      task_2:     0.9497,     0.9487\n",
      "      task_3:     0.9880,     0.9683\n",
      "      task_4:     0.9163,     0.9073\n",
      "\n",
      "epoch 32 validation\n",
      "\n",
      "epoch 32 val loss: 0.18011697, best val loss: 0.18084014\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9430,     0.9031\n",
      "      task_2:     0.9390,     0.9369\n",
      "      task_3:     0.9820,     0.9554\n",
      "      task_4:     0.8920,     0.8824\n",
      "\n",
      "epoch: 33\n",
      "\n",
      "training time 2.68\n",
      "Training loss: 0.133658\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9574,     0.9258\n",
      "      task_2:     0.9473,     0.9462\n",
      "      task_3:     0.9890,     0.9711\n",
      "      task_4:     0.9172,     0.9084\n",
      "\n",
      "epoch 33 validation\n",
      "\n",
      "epoch 33 val loss: 0.17862141, best val loss: 0.18011697\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9430,     0.9041\n",
      "      task_2:     0.9450,     0.9433\n",
      "      task_3:     0.9830,     0.9578\n",
      "      task_4:     0.8960,     0.8870\n",
      "\n",
      "epoch: 34\n",
      "\n",
      "training time 2.70\n",
      "Training loss: 0.122163\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9579,     0.9267\n",
      "      task_2:     0.9505,     0.9495\n",
      "      task_3:     0.9885,     0.9697\n",
      "      task_4:     0.9156,     0.9066\n",
      "\n",
      "epoch 34 validation\n",
      "\n",
      "epoch 34 val loss: 0.17899911, best val loss: 0.17862141\n",
      "patience counter is at 1 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9430,     0.9016\n",
      "      task_2:     0.9400,     0.9380\n",
      "      task_3:     0.9820,     0.9551\n",
      "      task_4:     0.8930,     0.8834\n",
      "\n",
      "epoch: 35\n",
      "\n",
      "training time 2.74\n",
      "Training loss: 0.127162\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9570,     0.9257\n",
      "      task_2:     0.9486,     0.9476\n",
      "      task_3:     0.9884,     0.9694\n",
      "      task_4:     0.9189,     0.9101\n",
      "\n",
      "epoch 35 validation\n",
      "\n",
      "epoch 35 val loss: 0.17766146, best val loss: 0.17862141\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9440,     0.9056\n",
      "      task_2:     0.9410,     0.9390\n",
      "      task_3:     0.9830,     0.9578\n",
      "      task_4:     0.8940,     0.8849\n",
      "\n",
      "epoch: 36\n",
      "\n",
      "training time 2.69\n",
      "Training loss: 0.122514\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9583,     0.9275\n",
      "      task_2:     0.9507,     0.9497\n",
      "      task_3:     0.9882,     0.9689\n",
      "      task_4:     0.9161,     0.9093\n",
      "\n",
      "epoch 36 validation\n",
      "\n",
      "epoch 36 val loss: 0.17751637, best val loss: 0.17766146\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9420,     0.9013\n",
      "      task_2:     0.9380,     0.9359\n",
      "      task_3:     0.9830,     0.9578\n",
      "      task_4:     0.8940,     0.8839\n",
      "\n",
      "epoch: 37\n",
      "\n",
      "training time 2.70\n",
      "Training loss: 0.123187\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9570,     0.9252\n",
      "      task_2:     0.9501,     0.9491\n",
      "      task_3:     0.9877,     0.9677\n",
      "      task_4:     0.9188,     0.9109\n",
      "\n",
      "epoch 37 validation\n",
      "\n",
      "epoch 37 val loss: 0.17675648, best val loss: 0.17751637\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9430,     0.9018\n",
      "      task_2:     0.9420,     0.9401\n",
      "      task_3:     0.9820,     0.9554\n",
      "      task_4:     0.8920,     0.8831\n",
      "\n",
      "epoch: 38\n",
      "\n",
      "training time 2.70\n",
      "Training loss: 0.120820\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9578,     0.9269\n",
      "      task_2:     0.9489,     0.9478\n",
      "      task_3:     0.9877,     0.9676\n",
      "      task_4:     0.9199,     0.9122\n",
      "\n",
      "epoch 38 validation\n",
      "\n",
      "epoch 38 val loss: 0.17637289, best val loss: 0.17675648\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9450,     0.9057\n",
      "      task_2:     0.9440,     0.9421\n",
      "      task_3:     0.9810,     0.9528\n",
      "      task_4:     0.8930,     0.8831\n",
      "\n",
      "epoch: 39\n",
      "\n",
      "training time 2.68\n",
      "Training loss: 0.130363\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9580,     0.9278\n",
      "      task_2:     0.9525,     0.9515\n",
      "      task_3:     0.9881,     0.9687\n",
      "      task_4:     0.9185,     0.9095\n",
      "\n",
      "epoch 39 validation\n",
      "\n",
      "epoch 39 val loss: 0.17501765, best val loss: 0.17637289\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9460,     0.9064\n",
      "      task_2:     0.9420,     0.9401\n",
      "      task_3:     0.9810,     0.9532\n",
      "      task_4:     0.8950,     0.8856\n",
      "\n",
      "epoch: 40\n",
      "\n",
      "training time 2.72\n",
      "Training loss: 0.120877\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9591,     0.9294\n",
      "      task_2:     0.9509,     0.9499\n",
      "      task_3:     0.9887,     0.9702\n",
      "      task_4:     0.9189,     0.9101\n",
      "\n",
      "epoch 40 validation\n",
      "\n",
      "epoch 40 val loss: 0.17492682, best val loss: 0.17501765\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9450,     0.9057\n",
      "      task_2:     0.9420,     0.9401\n",
      "      task_3:     0.9840,     0.9598\n",
      "      task_4:     0.8940,     0.8849\n",
      "\n",
      "epoch: 41\n",
      "\n",
      "training time 2.73\n",
      "Training loss: 0.131310\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9596,     0.9306\n",
      "      task_2:     0.9497,     0.9487\n",
      "      task_3:     0.9885,     0.9696\n",
      "      task_4:     0.9174,     0.9097\n",
      "\n",
      "epoch 41 validation\n",
      "\n",
      "epoch 41 val loss: 0.17399503, best val loss: 0.17492682\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9450,     0.9057\n",
      "      task_2:     0.9420,     0.9401\n",
      "      task_3:     0.9830,     0.9574\n",
      "      task_4:     0.8940,     0.8836\n",
      "\n",
      "epoch: 42\n",
      "\n",
      "training time 2.68\n",
      "Training loss: 0.107280\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9571,     0.9245\n",
      "      task_2:     0.9528,     0.9518\n",
      "      task_3:     0.9885,     0.9698\n",
      "      task_4:     0.9189,     0.9112\n",
      "\n",
      "epoch 42 validation\n",
      "\n",
      "epoch 42 val loss: 0.17363767, best val loss: 0.17399503\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9450,     0.9071\n",
      "      task_2:     0.9430,     0.9412\n",
      "      task_3:     0.9840,     0.9601\n",
      "      task_4:     0.8950,     0.8860\n",
      "\n",
      "epoch: 43\n",
      "\n",
      "training time 2.64\n",
      "Training loss: 0.121578\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9593,     0.9296\n",
      "      task_2:     0.9527,     0.9518\n",
      "      task_3:     0.9889,     0.9705\n",
      "      task_4:     0.9197,     0.9120\n",
      "\n",
      "epoch 43 validation\n",
      "\n",
      "epoch 43 val loss: 0.17259409, best val loss: 0.17363767\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9460,     0.9098\n",
      "      task_2:     0.9440,     0.9422\n",
      "      task_3:     0.9870,     0.9669\n",
      "      task_4:     0.8970,     0.8872\n",
      "\n",
      "epoch: 44\n",
      "\n",
      "training time 2.65\n",
      "Training loss: 0.107265\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9589,     0.9282\n",
      "      task_2:     0.9515,     0.9505\n",
      "      task_3:     0.9888,     0.9705\n",
      "      task_4:     0.9190,     0.9108\n",
      "\n",
      "epoch 44 validation\n",
      "\n",
      "epoch 44 val loss: 0.17256695, best val loss: 0.17259409\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9450,     0.9068\n",
      "      task_2:     0.9450,     0.9432\n",
      "      task_3:     0.9840,     0.9598\n",
      "      task_4:     0.8950,     0.8837\n",
      "\n",
      "epoch: 45\n",
      "\n",
      "training time 2.65\n",
      "Training loss: 0.110368\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9578,     0.9279\n",
      "      task_2:     0.9531,     0.9522\n",
      "      task_3:     0.9884,     0.9694\n",
      "      task_4:     0.9207,     0.9133\n",
      "\n",
      "epoch 45 validation\n",
      "\n",
      "epoch 45 val loss: 0.17239987, best val loss: 0.17256695\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9440,     0.9051\n",
      "      task_2:     0.9450,     0.9432\n",
      "      task_3:     0.9850,     0.9624\n",
      "      task_4:     0.8930,     0.8806\n",
      "\n",
      "epoch: 46\n",
      "\n",
      "training time 2.65\n",
      "Training loss: 0.104779\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9579,     0.9281\n",
      "      task_2:     0.9520,     0.9510\n",
      "      task_3:     0.9886,     0.9699\n",
      "      task_4:     0.9225,     0.9148\n",
      "\n",
      "epoch 46 validation\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46 val loss: 0.17089294, best val loss: 0.17239987\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9450,     0.9070\n",
      "      task_2:     0.9440,     0.9422\n",
      "      task_3:     0.9870,     0.9672\n",
      "      task_4:     0.8920,     0.8786\n",
      "\n",
      "epoch: 47\n",
      "\n",
      "training time 2.64\n",
      "Training loss: 0.112866\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9590,     0.9280\n",
      "      task_2:     0.9531,     0.9522\n",
      "      task_3:     0.9881,     0.9687\n",
      "      task_4:     0.9200,     0.9125\n",
      "\n",
      "epoch 47 validation\n",
      "\n",
      "epoch 47 val loss: 0.17182706, best val loss: 0.17089294\n",
      "patience counter is at 1 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9450,     0.9070\n",
      "      task_2:     0.9420,     0.9400\n",
      "      task_3:     0.9860,     0.9648\n",
      "      task_4:     0.8960,     0.8836\n",
      "\n",
      "epoch: 48\n",
      "\n",
      "training time 2.64\n",
      "Training loss: 0.113777\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9602,     0.9294\n",
      "      task_2:     0.9522,     0.9512\n",
      "      task_3:     0.9893,     0.9716\n",
      "      task_4:     0.9213,     0.9139\n",
      "\n",
      "epoch 48 validation\n",
      "\n",
      "epoch 48 val loss: 0.17090924, best val loss: 0.17089294\n",
      "patience counter is at 2 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9460,     0.9086\n",
      "      task_2:     0.9430,     0.9411\n",
      "      task_3:     0.9860,     0.9648\n",
      "      task_4:     0.8930,     0.8803\n",
      "\n",
      "epoch: 49\n",
      "\n",
      "training time 2.64\n",
      "Training loss: 0.100602\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9609,     0.9318\n",
      "      task_2:     0.9507,     0.9497\n",
      "      task_3:     0.9894,     0.9720\n",
      "      task_4:     0.9217,     0.9130\n",
      "\n",
      "epoch 49 validation\n",
      "\n",
      "epoch 49 val loss: 0.17032377, best val loss: 0.17089294\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9470,     0.9094\n",
      "      task_2:     0.9440,     0.9422\n",
      "      task_3:     0.9850,     0.9624\n",
      "      task_4:     0.8960,     0.8836\n",
      "\n",
      "epoch: 50\n",
      "\n",
      "training time 2.62\n",
      "Training loss: 0.106101\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9599,     0.9297\n",
      "      task_2:     0.9521,     0.9512\n",
      "      task_3:     0.9887,     0.9703\n",
      "      task_4:     0.9185,     0.9105\n",
      "\n",
      "epoch 50 validation\n",
      "\n",
      "epoch 50 val loss: 0.16950647, best val loss: 0.17032377\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9420,     0.9007\n",
      "      task_2:     0.9470,     0.9453\n",
      "      task_3:     0.9860,     0.9648\n",
      "      task_4:     0.8920,     0.8795\n",
      "\n",
      "epoch: 51\n",
      "\n",
      "training time 2.65\n",
      "Training loss: 0.116054\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9615,     0.9340\n",
      "      task_2:     0.9519,     0.9509\n",
      "      task_3:     0.9894,     0.9721\n",
      "      task_4:     0.9215,     0.9130\n",
      "\n",
      "epoch 51 validation\n",
      "\n",
      "epoch 51 val loss: 0.16928869, best val loss: 0.16950647\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9480,     0.9099\n",
      "      task_2:     0.9460,     0.9443\n",
      "      task_3:     0.9860,     0.9648\n",
      "      task_4:     0.8940,     0.8811\n",
      "\n",
      "epoch: 52\n",
      "\n",
      "training time 2.71\n",
      "Training loss: 0.104226\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9612,     0.9335\n",
      "      task_2:     0.9523,     0.9514\n",
      "      task_3:     0.9899,     0.9733\n",
      "      task_4:     0.9212,     0.9143\n",
      "\n",
      "epoch 52 validation\n",
      "\n",
      "epoch 52 val loss: 0.16878203, best val loss: 0.16928869\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9480,     0.9124\n",
      "      task_2:     0.9470,     0.9452\n",
      "      task_3:     0.9870,     0.9672\n",
      "      task_4:     0.8970,     0.8837\n",
      "\n",
      "epoch: 53\n",
      "\n",
      "training time 2.67\n",
      "Training loss: 0.106552\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9601,     0.9322\n",
      "      task_2:     0.9516,     0.9506\n",
      "      task_3:     0.9899,     0.9735\n",
      "      task_4:     0.9230,     0.9155\n",
      "\n",
      "epoch 53 validation\n",
      "\n",
      "epoch 53 val loss: 0.16858293, best val loss: 0.16878203\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9470,     0.9095\n",
      "      task_2:     0.9450,     0.9432\n",
      "      task_3:     0.9870,     0.9672\n",
      "      task_4:     0.8960,     0.8823\n",
      "\n",
      "epoch: 54\n",
      "\n",
      "training time 2.65\n",
      "Training loss: 0.100356\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9603,     0.9323\n",
      "      task_2:     0.9533,     0.9523\n",
      "      task_3:     0.9895,     0.9723\n",
      "      task_4:     0.9215,     0.9139\n",
      "\n",
      "epoch 54 validation\n",
      "\n",
      "epoch 54 val loss: 0.16732489, best val loss: 0.16858293\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9470,     0.9096\n",
      "      task_2:     0.9440,     0.9423\n",
      "      task_3:     0.9880,     0.9696\n",
      "      task_4:     0.8940,     0.8801\n",
      "\n",
      "epoch: 55\n",
      "\n",
      "training time 2.65\n",
      "Training loss: 0.091596\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9596,     0.9301\n",
      "      task_2:     0.9527,     0.9518\n",
      "      task_3:     0.9901,     0.9738\n",
      "      task_4:     0.9209,     0.9134\n",
      "\n",
      "epoch 55 validation\n",
      "\n",
      "epoch 55 val loss: 0.16861740, best val loss: 0.16732489\n",
      "patience counter is at 1 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9460,     0.9062\n",
      "      task_2:     0.9460,     0.9442\n",
      "      task_3:     0.9870,     0.9669\n",
      "      task_4:     0.8940,     0.8801\n",
      "\n",
      "epoch: 56\n",
      "\n",
      "training time 2.66\n",
      "Training loss: 0.093961\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9621,     0.9350\n",
      "      task_2:     0.9524,     0.9514\n",
      "      task_3:     0.9897,     0.9728\n",
      "      task_4:     0.9231,     0.9154\n",
      "\n",
      "epoch 56 validation\n",
      "\n",
      "epoch 56 val loss: 0.16775694, best val loss: 0.16732489\n",
      "patience counter is at 2 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9460,     0.9065\n",
      "      task_2:     0.9440,     0.9422\n",
      "      task_3:     0.9880,     0.9696\n",
      "      task_4:     0.8950,     0.8818\n",
      "\n",
      "epoch: 57\n",
      "\n",
      "training time 2.65\n",
      "Training loss: 0.098781\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9641,     0.9384\n",
      "      task_2:     0.9547,     0.9537\n",
      "      task_3:     0.9902,     0.9742\n",
      "      task_4:     0.9253,     0.9186\n",
      "\n",
      "epoch 57 validation\n",
      "\n",
      "epoch 57 val loss: 0.16733214, best val loss: 0.16732489\n",
      "patience counter is at 3 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9490,     0.9132\n",
      "      task_2:     0.9450,     0.9431\n",
      "      task_3:     0.9870,     0.9672\n",
      "      task_4:     0.8960,     0.8826\n",
      "\n",
      "epoch: 58\n",
      "\n",
      "training time 2.67\n",
      "Training loss: 0.110087\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9634,     0.9384\n",
      "      task_2:     0.9519,     0.9509\n",
      "      task_3:     0.9901,     0.9739\n",
      "      task_4:     0.9234,     0.9174\n",
      "\n",
      "epoch 58 validation\n",
      "\n",
      "epoch 58 val loss: 0.16692751, best val loss: 0.16732489\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9450,     0.9061\n",
      "      task_2:     0.9460,     0.9442\n",
      "      task_3:     0.9880,     0.9696\n",
      "      task_4:     0.8950,     0.8809\n",
      "\n",
      "epoch: 59\n",
      "\n",
      "training time 2.68\n",
      "Training loss: 0.098378\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9624,     0.9354\n",
      "      task_2:     0.9527,     0.9517\n",
      "      task_3:     0.9901,     0.9738\n",
      "      task_4:     0.9221,     0.9157\n",
      "\n",
      "epoch 59 validation\n",
      "\n",
      "epoch 59 val loss: 0.16635126, best val loss: 0.16692751\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9480,     0.9095\n",
      "      task_2:     0.9450,     0.9432\n",
      "      task_3:     0.9890,     0.9722\n",
      "      task_4:     0.8950,     0.8818\n",
      "\n",
      "epoch: 60\n",
      "\n",
      "training time 2.66\n",
      "Training loss: 0.095211\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9626,     0.9362\n",
      "      task_2:     0.9529,     0.9519\n",
      "      task_3:     0.9899,     0.9735\n",
      "      task_4:     0.9221,     0.9139\n",
      "\n",
      "epoch 60 validation\n",
      "\n",
      "epoch 60 val loss: 0.16623835, best val loss: 0.16635126\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9460,     0.9054\n",
      "      task_2:     0.9460,     0.9442\n",
      "      task_3:     0.9870,     0.9672\n",
      "      task_4:     0.8960,     0.8823\n",
      "\n",
      "epoch: 61\n",
      "\n",
      "training time 2.66\n",
      "Training loss: 0.087972\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9623,     0.9363\n",
      "      task_2:     0.9537,     0.9527\n",
      "      task_3:     0.9898,     0.9731\n",
      "      task_4:     0.9257,     0.9177\n",
      "\n",
      "epoch 61 validation\n",
      "\n",
      "epoch 61 val loss: 0.16617339, best val loss: 0.16623835\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9440,     0.9029\n",
      "      task_2:     0.9460,     0.9443\n",
      "      task_3:     0.9880,     0.9696\n",
      "      task_4:     0.8940,     0.8814\n",
      "\n",
      "epoch: 62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training time 2.66\n",
      "Training loss: 0.098817\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9621,     0.9361\n",
      "      task_2:     0.9533,     0.9524\n",
      "      task_3:     0.9899,     0.9735\n",
      "      task_4:     0.9239,     0.9172\n",
      "\n",
      "epoch 62 validation\n",
      "\n",
      "epoch 62 val loss: 0.16524484, best val loss: 0.16617339\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9470,     0.9093\n",
      "      task_2:     0.9460,     0.9443\n",
      "      task_3:     0.9880,     0.9696\n",
      "      task_4:     0.8940,     0.8801\n",
      "\n",
      "epoch: 63\n",
      "\n",
      "training time 2.66\n",
      "Training loss: 0.097334\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9634,     0.9384\n",
      "      task_2:     0.9536,     0.9526\n",
      "      task_3:     0.9903,     0.9743\n",
      "      task_4:     0.9243,     0.9168\n",
      "\n",
      "epoch 63 validation\n",
      "\n",
      "epoch 63 val loss: 0.16559815, best val loss: 0.16524484\n",
      "patience counter is at 1 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9470,     0.9070\n",
      "      task_2:     0.9460,     0.9443\n",
      "      task_3:     0.9880,     0.9696\n",
      "      task_4:     0.8950,     0.8815\n",
      "\n",
      "epoch: 64\n",
      "\n",
      "training time 2.66\n",
      "Training loss: 0.100536\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9617,     0.9357\n",
      "      task_2:     0.9536,     0.9527\n",
      "      task_3:     0.9895,     0.9724\n",
      "      task_4:     0.9240,     0.9159\n",
      "\n",
      "epoch 64 validation\n",
      "\n",
      "epoch 64 val loss: 0.16549269, best val loss: 0.16524484\n",
      "patience counter is at 2 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9440,     0.9011\n",
      "      task_2:     0.9480,     0.9463\n",
      "      task_3:     0.9870,     0.9669\n",
      "      task_4:     0.8940,     0.8808\n",
      "\n",
      "epoch: 65\n",
      "\n",
      "training time 2.66\n",
      "Training loss: 0.088081\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9653,     0.9404\n",
      "      task_2:     0.9549,     0.9540\n",
      "      task_3:     0.9899,     0.9733\n",
      "      task_4:     0.9245,     0.9172\n",
      "\n",
      "epoch 65 validation\n",
      "\n",
      "epoch 65 val loss: 0.16483838, best val loss: 0.16524484\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9470,     0.9073\n",
      "      task_2:     0.9470,     0.9453\n",
      "      task_3:     0.9860,     0.9642\n",
      "      task_4:     0.8980,     0.8845\n",
      "\n",
      "epoch: 66\n",
      "\n",
      "training time 2.66\n",
      "Training loss: 0.092390\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9614,     0.9333\n",
      "      task_2:     0.9555,     0.9546\n",
      "      task_3:     0.9899,     0.9735\n",
      "      task_4:     0.9260,     0.9188\n",
      "\n",
      "epoch 66 validation\n",
      "\n",
      "epoch 66 val loss: 0.16445279, best val loss: 0.16483838\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9480,     0.9091\n",
      "      task_2:     0.9460,     0.9442\n",
      "      task_3:     0.9860,     0.9642\n",
      "      task_4:     0.8990,     0.8856\n",
      "\n",
      "epoch: 67\n",
      "\n",
      "training time 2.66\n",
      "Training loss: 0.079938\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9649,     0.9407\n",
      "      task_2:     0.9539,     0.9529\n",
      "      task_3:     0.9901,     0.9738\n",
      "      task_4:     0.9255,     0.9187\n",
      "\n",
      "epoch 67 validation\n",
      "\n",
      "epoch 67 val loss: 0.16389206, best val loss: 0.16445279\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9460,     0.9065\n",
      "      task_2:     0.9470,     0.9453\n",
      "      task_3:     0.9880,     0.9698\n",
      "      task_4:     0.8990,     0.8869\n",
      "\n",
      "epoch: 68\n",
      "\n",
      "training time 2.67\n",
      "Training loss: 0.081260\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9636,     0.9380\n",
      "      task_2:     0.9546,     0.9537\n",
      "      task_3:     0.9902,     0.9742\n",
      "      task_4:     0.9284,     0.9216\n",
      "\n",
      "epoch 68 validation\n",
      "\n",
      "epoch 68 val loss: 0.16349284, best val loss: 0.16389206\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9460,     0.9067\n",
      "      task_2:     0.9450,     0.9432\n",
      "      task_3:     0.9880,     0.9696\n",
      "      task_4:     0.8970,     0.8830\n",
      "\n",
      "epoch: 69\n",
      "\n",
      "training time 2.72\n",
      "Training loss: 0.086780\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9629,     0.9373\n",
      "      task_2:     0.9527,     0.9518\n",
      "      task_3:     0.9898,     0.9731\n",
      "      task_4:     0.9255,     0.9180\n",
      "\n",
      "epoch 69 validation\n",
      "\n",
      "epoch 69 val loss: 0.16256922, best val loss: 0.16349284\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9480,     0.9102\n",
      "      task_2:     0.9450,     0.9431\n",
      "      task_3:     0.9870,     0.9669\n",
      "      task_4:     0.8960,     0.8826\n",
      "\n",
      "epoch: 70\n",
      "\n",
      "training time 2.69\n",
      "Training loss: 0.086311\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9626,     0.9356\n",
      "      task_2:     0.9526,     0.9516\n",
      "      task_3:     0.9904,     0.9747\n",
      "      task_4:     0.9257,     0.9174\n",
      "\n",
      "epoch 70 validation\n",
      "\n",
      "epoch 70 val loss: 0.16238520, best val loss: 0.16256922\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9470,     0.9086\n",
      "      task_2:     0.9470,     0.9453\n",
      "      task_3:     0.9870,     0.9669\n",
      "      task_4:     0.8980,     0.8851\n",
      "\n",
      "epoch: 71\n",
      "\n",
      "training time 2.73\n",
      "Training loss: 0.088349\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9636,     0.9375\n",
      "      task_2:     0.9565,     0.9557\n",
      "      task_3:     0.9901,     0.9738\n",
      "      task_4:     0.9278,     0.9213\n",
      "\n",
      "epoch 71 validation\n",
      "\n",
      "epoch 71 val loss: 0.16189647, best val loss: 0.16238520\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9460,     0.9078\n",
      "      task_2:     0.9470,     0.9453\n",
      "      task_3:     0.9870,     0.9669\n",
      "      task_4:     0.8990,     0.8860\n",
      "\n",
      "epoch: 72\n",
      "\n",
      "training time 2.61\n",
      "Training loss: 0.081836\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9655,     0.9418\n",
      "      task_2:     0.9553,     0.9544\n",
      "      task_3:     0.9901,     0.9737\n",
      "      task_4:     0.9270,     0.9195\n",
      "\n",
      "epoch 72 validation\n",
      "\n",
      "epoch 72 val loss: 0.16197427, best val loss: 0.16189647\n",
      "patience counter is at 1 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9480,     0.9102\n",
      "      task_2:     0.9470,     0.9453\n",
      "      task_3:     0.9870,     0.9672\n",
      "      task_4:     0.8970,     0.8831\n",
      "\n",
      "epoch: 73\n",
      "\n",
      "training time 2.63\n",
      "Training loss: 0.083411\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9635,     0.9390\n",
      "      task_2:     0.9539,     0.9530\n",
      "      task_3:     0.9911,     0.9764\n",
      "      task_4:     0.9268,     0.9200\n",
      "\n",
      "epoch 73 validation\n",
      "\n",
      "epoch 73 val loss: 0.16195690, best val loss: 0.16189647\n",
      "patience counter is at 2 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9470,     0.9070\n",
      "      task_2:     0.9440,     0.9421\n",
      "      task_3:     0.9870,     0.9669\n",
      "      task_4:     0.9000,     0.8870\n",
      "\n",
      "epoch: 74\n",
      "\n",
      "training time 2.63\n",
      "Training loss: 0.089410\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9651,     0.9393\n",
      "      task_2:     0.9525,     0.9516\n",
      "      task_3:     0.9900,     0.9736\n",
      "      task_4:     0.9280,     0.9219\n",
      "\n",
      "epoch 74 validation\n",
      "\n",
      "epoch 74 val loss: 0.16195725, best val loss: 0.16189647\n",
      "patience counter is at 3 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9460,     0.9065\n",
      "      task_2:     0.9460,     0.9442\n",
      "      task_3:     0.9890,     0.9722\n",
      "      task_4:     0.8980,     0.8839\n",
      "\n",
      "epoch: 75\n",
      "\n",
      "training time 2.63\n",
      "Training loss: 0.083315\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9644,     0.9385\n",
      "      task_2:     0.9572,     0.9563\n",
      "      task_3:     0.9895,     0.9722\n",
      "      task_4:     0.9261,     0.9184\n",
      "\n",
      "epoch 75 validation\n",
      "\n",
      "epoch 75 val loss: 0.16146573, best val loss: 0.16189647\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9460,     0.9051\n",
      "      task_2:     0.9480,     0.9463\n",
      "      task_3:     0.9890,     0.9722\n",
      "      task_4:     0.8990,     0.8856\n",
      "\n",
      "epoch: 76\n",
      "\n",
      "training time 2.63\n",
      "Training loss: 0.081316\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9647,     0.9405\n",
      "      task_2:     0.9541,     0.9531\n",
      "      task_3:     0.9909,     0.9759\n",
      "      task_4:     0.9265,     0.9194\n",
      "\n",
      "epoch 76 validation\n",
      "\n",
      "epoch 76 val loss: 0.16173573, best val loss: 0.16146573\n",
      "patience counter is at 1 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9480,     0.9090\n",
      "      task_2:     0.9470,     0.9453\n",
      "      task_3:     0.9860,     0.9642\n",
      "      task_4:     0.8970,     0.8834\n",
      "\n",
      "epoch: 77\n",
      "\n",
      "training time 2.63\n",
      "Training loss: 0.076217\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9636,     0.9386\n",
      "      task_2:     0.9579,     0.9571\n",
      "      task_3:     0.9902,     0.9741\n",
      "      task_4:     0.9255,     0.9177\n",
      "\n",
      "epoch 77 validation\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77 val loss: 0.16139594, best val loss: 0.16146573\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9470,     0.9086\n",
      "      task_2:     0.9480,     0.9463\n",
      "      task_3:     0.9860,     0.9642\n",
      "      task_4:     0.9010,     0.8871\n",
      "\n",
      "epoch: 78\n",
      "\n",
      "training time 2.63\n",
      "Training loss: 0.086054\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9639,     0.9389\n",
      "      task_2:     0.9553,     0.9544\n",
      "      task_3:     0.9912,     0.9768\n",
      "      task_4:     0.9246,     0.9165\n",
      "\n",
      "epoch 78 validation\n",
      "\n",
      "epoch 78 val loss: 0.16086859, best val loss: 0.16139594\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9480,     0.9086\n",
      "      task_2:     0.9470,     0.9454\n",
      "      task_3:     0.9860,     0.9645\n",
      "      task_4:     0.9020,     0.8879\n",
      "\n",
      "epoch: 79\n",
      "\n",
      "training time 2.63\n",
      "Training loss: 0.073876\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9641,     0.9399\n",
      "      task_2:     0.9573,     0.9565\n",
      "      task_3:     0.9908,     0.9757\n",
      "      task_4:     0.9285,     0.9212\n",
      "\n",
      "epoch 79 validation\n",
      "\n",
      "epoch 79 val loss: 0.16047622, best val loss: 0.16086859\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9480,     0.9090\n",
      "      task_2:     0.9480,     0.9463\n",
      "      task_3:     0.9870,     0.9667\n",
      "      task_4:     0.8990,     0.8859\n",
      "\n",
      "epoch: 80\n",
      "\n",
      "training time 2.63\n",
      "Training loss: 0.069667\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9669,     0.9446\n",
      "      task_2:     0.9550,     0.9541\n",
      "      task_3:     0.9901,     0.9739\n",
      "      task_4:     0.9285,     0.9225\n",
      "\n",
      "epoch 80 validation\n",
      "\n",
      "epoch 80 val loss: 0.15969558, best val loss: 0.16047622\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9480,     0.9090\n",
      "      task_2:     0.9460,     0.9443\n",
      "      task_3:     0.9870,     0.9667\n",
      "      task_4:     0.9010,     0.8888\n",
      "\n",
      "epoch: 81\n",
      "\n",
      "training time 2.64\n",
      "Training loss: 0.082665\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9654,     0.9425\n",
      "      task_2:     0.9549,     0.9540\n",
      "      task_3:     0.9909,     0.9760\n",
      "      task_4:     0.9297,     0.9228\n",
      "\n",
      "epoch 81 validation\n",
      "\n",
      "epoch 81 val loss: 0.15960832, best val loss: 0.15969558\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9490,     0.9123\n",
      "      task_2:     0.9480,     0.9463\n",
      "      task_3:     0.9870,     0.9667\n",
      "      task_4:     0.8990,     0.8866\n",
      "\n",
      "epoch: 82\n",
      "\n",
      "training time 2.64\n",
      "Training loss: 0.080874\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9637,     0.9374\n",
      "      task_2:     0.9559,     0.9550\n",
      "      task_3:     0.9904,     0.9747\n",
      "      task_4:     0.9267,     0.9199\n",
      "\n",
      "epoch 82 validation\n",
      "\n",
      "epoch 82 val loss: 0.15993675, best val loss: 0.15960832\n",
      "patience counter is at 1 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9480,     0.9090\n",
      "      task_2:     0.9470,     0.9452\n",
      "      task_3:     0.9870,     0.9667\n",
      "      task_4:     0.9020,     0.8899\n",
      "\n",
      "epoch: 83\n",
      "\n",
      "training time 2.61\n",
      "Training loss: 0.074769\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9673,     0.9434\n",
      "      task_2:     0.9555,     0.9546\n",
      "      task_3:     0.9917,     0.9780\n",
      "      task_4:     0.9277,     0.9215\n",
      "\n",
      "epoch 83 validation\n",
      "\n",
      "epoch 83 val loss: 0.16031170, best val loss: 0.15960832\n",
      "patience counter is at 2 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9490,     0.9119\n",
      "      task_2:     0.9450,     0.9432\n",
      "      task_3:     0.9860,     0.9645\n",
      "      task_4:     0.9010,     0.8871\n",
      "\n",
      "epoch: 84\n",
      "\n",
      "training time 2.61\n",
      "Training loss: 0.076916\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9665,     0.9431\n",
      "      task_2:     0.9573,     0.9565\n",
      "      task_3:     0.9903,     0.9745\n",
      "      task_4:     0.9288,     0.9210\n",
      "\n",
      "epoch 84 validation\n",
      "\n",
      "epoch 84 val loss: 0.15949336, best val loss: 0.15960832\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9490,     0.9117\n",
      "      task_2:     0.9460,     0.9443\n",
      "      task_3:     0.9870,     0.9669\n",
      "      task_4:     0.8980,     0.8845\n",
      "\n",
      "epoch: 85\n",
      "\n",
      "training time 2.61\n",
      "Training loss: 0.092630\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9661,     0.9426\n",
      "      task_2:     0.9575,     0.9566\n",
      "      task_3:     0.9899,     0.9735\n",
      "      task_4:     0.9272,     0.9205\n",
      "\n",
      "epoch 85 validation\n",
      "\n",
      "epoch 85 val loss: 0.15918371, best val loss: 0.15949336\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9480,     0.9100\n",
      "      task_2:     0.9490,     0.9474\n",
      "      task_3:     0.9880,     0.9696\n",
      "      task_4:     0.9010,     0.8868\n",
      "\n",
      "epoch: 86\n",
      "\n",
      "training time 2.70\n",
      "Training loss: 0.074101\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9655,     0.9415\n",
      "      task_2:     0.9576,     0.9567\n",
      "      task_3:     0.9909,     0.9761\n",
      "      task_4:     0.9311,     0.9242\n",
      "\n",
      "epoch 86 validation\n",
      "\n",
      "epoch 86 val loss: 0.15944257, best val loss: 0.15918371\n",
      "patience counter is at 1 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9480,     0.9104\n",
      "      task_2:     0.9480,     0.9463\n",
      "      task_3:     0.9890,     0.9720\n",
      "      task_4:     0.9020,     0.8886\n",
      "\n",
      "epoch: 87\n",
      "\n",
      "training time 2.62\n",
      "Training loss: 0.076537\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9649,     0.9401\n",
      "      task_2:     0.9571,     0.9563\n",
      "      task_3:     0.9911,     0.9767\n",
      "      task_4:     0.9307,     0.9243\n",
      "\n",
      "epoch 87 validation\n",
      "\n",
      "epoch 87 val loss: 0.15909633, best val loss: 0.15918371\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9490,     0.9120\n",
      "      task_2:     0.9470,     0.9453\n",
      "      task_3:     0.9860,     0.9642\n",
      "      task_4:     0.9000,     0.8870\n",
      "\n",
      "epoch: 88\n",
      "\n",
      "training time 2.59\n",
      "Training loss: 0.081469\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9651,     0.9410\n",
      "      task_2:     0.9571,     0.9563\n",
      "      task_3:     0.9907,     0.9755\n",
      "      task_4:     0.9279,     0.9211\n",
      "\n",
      "epoch 88 validation\n",
      "\n",
      "epoch 88 val loss: 0.15890061, best val loss: 0.15909633\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9480,     0.9120\n",
      "      task_2:     0.9470,     0.9453\n",
      "      task_3:     0.9870,     0.9674\n",
      "      task_4:     0.9020,     0.8879\n",
      "\n",
      "epoch: 89\n",
      "\n",
      "training time 2.59\n",
      "Training loss: 0.063215\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9661,     0.9420\n",
      "      task_2:     0.9555,     0.9546\n",
      "      task_3:     0.9921,     0.9791\n",
      "      task_4:     0.9336,     0.9275\n",
      "\n",
      "epoch 89 validation\n",
      "\n",
      "epoch 89 val loss: 0.15868189, best val loss: 0.15890061\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9490,     0.9132\n",
      "      task_2:     0.9490,     0.9474\n",
      "      task_3:     0.9860,     0.9642\n",
      "      task_4:     0.9000,     0.8864\n",
      "\n",
      "epoch: 90\n",
      "\n",
      "training time 2.59\n",
      "Training loss: 0.076298\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9667,     0.9436\n",
      "      task_2:     0.9577,     0.9568\n",
      "      task_3:     0.9903,     0.9743\n",
      "      task_4:     0.9294,     0.9222\n",
      "\n",
      "epoch 90 validation\n",
      "\n",
      "epoch 90 val loss: 0.15864025, best val loss: 0.15868189\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9490,     0.9136\n",
      "      task_2:     0.9480,     0.9463\n",
      "      task_3:     0.9880,     0.9698\n",
      "      task_4:     0.9020,     0.8889\n",
      "\n",
      "epoch: 91\n",
      "\n",
      "training time 2.59\n",
      "Training loss: 0.068740\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9662,     0.9432\n",
      "      task_2:     0.9552,     0.9543\n",
      "      task_3:     0.9915,     0.9775\n",
      "      task_4:     0.9306,     0.9237\n",
      "\n",
      "epoch 91 validation\n",
      "\n",
      "epoch 91 val loss: 0.15862747, best val loss: 0.15864025\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9470,     0.9088\n",
      "      task_2:     0.9480,     0.9463\n",
      "      task_3:     0.9860,     0.9642\n",
      "      task_4:     0.9020,     0.8896\n",
      "\n",
      "epoch: 92\n",
      "\n",
      "training time 2.60\n",
      "Training loss: 0.068286\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9659,     0.9444\n",
      "      task_2:     0.9552,     0.9543\n",
      "      task_3:     0.9917,     0.9782\n",
      "      task_4:     0.9331,     0.9261\n",
      "\n",
      "epoch 92 validation\n",
      "\n",
      "epoch 92 val loss: 0.15820234, best val loss: 0.15862747\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9480,     0.9124\n",
      "      task_2:     0.9460,     0.9443\n",
      "      task_3:     0.9870,     0.9667\n",
      "      task_4:     0.9030,     0.8893\n",
      "\n",
      "epoch: 93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training time 2.64\n",
      "Training loss: 0.073369\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9671,     0.9447\n",
      "      task_2:     0.9569,     0.9561\n",
      "      task_3:     0.9913,     0.9771\n",
      "      task_4:     0.9310,     0.9246\n",
      "\n",
      "epoch 93 validation\n",
      "\n",
      "epoch 93 val loss: 0.15785061, best val loss: 0.15820234\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9490,     0.9129\n",
      "      task_2:     0.9460,     0.9443\n",
      "      task_3:     0.9860,     0.9642\n",
      "      task_4:     0.9000,     0.8867\n",
      "\n",
      "epoch: 94\n",
      "\n",
      "training time 2.64\n",
      "Training loss: 0.071946\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9663,     0.9426\n",
      "      task_2:     0.9559,     0.9550\n",
      "      task_3:     0.9908,     0.9757\n",
      "      task_4:     0.9331,     0.9267\n",
      "\n",
      "epoch 94 validation\n",
      "\n",
      "epoch 94 val loss: 0.15819725, best val loss: 0.15785061\n",
      "patience counter is at 1 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9490,     0.9113\n",
      "      task_2:     0.9490,     0.9474\n",
      "      task_3:     0.9870,     0.9667\n",
      "      task_4:     0.9010,     0.8874\n",
      "\n",
      "epoch: 95\n",
      "\n",
      "training time 2.65\n",
      "Training loss: 0.067665\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9662,     0.9434\n",
      "      task_2:     0.9580,     0.9572\n",
      "      task_3:     0.9920,     0.9789\n",
      "      task_4:     0.9314,     0.9266\n",
      "\n",
      "epoch 95 validation\n",
      "\n",
      "epoch 95 val loss: 0.15735714, best val loss: 0.15785061\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9470,     0.9098\n",
      "      task_2:     0.9490,     0.9474\n",
      "      task_3:     0.9870,     0.9669\n",
      "      task_4:     0.9000,     0.8857\n",
      "\n",
      "epoch: 96\n",
      "\n",
      "training time 2.64\n",
      "Training loss: 0.079900\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9673,     0.9453\n",
      "      task_2:     0.9574,     0.9566\n",
      "      task_3:     0.9913,     0.9771\n",
      "      task_4:     0.9297,     0.9229\n",
      "\n",
      "epoch 96 validation\n",
      "\n",
      "epoch 96 val loss: 0.15735447, best val loss: 0.15735714\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9460,     0.9085\n",
      "      task_2:     0.9480,     0.9463\n",
      "      task_3:     0.9880,     0.9694\n",
      "      task_4:     0.9020,     0.8875\n",
      "\n",
      "epoch: 97\n",
      "\n",
      "training time 2.66\n",
      "Training loss: 0.073744\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9665,     0.9447\n",
      "      task_2:     0.9587,     0.9579\n",
      "      task_3:     0.9919,     0.9787\n",
      "      task_4:     0.9314,     0.9244\n",
      "\n",
      "epoch 97 validation\n",
      "\n",
      "epoch 97 val loss: 0.15681676, best val loss: 0.15735447\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9450,     0.9063\n",
      "      task_2:     0.9490,     0.9474\n",
      "      task_3:     0.9870,     0.9667\n",
      "      task_4:     0.8990,     0.8833\n",
      "\n",
      "epoch: 98\n",
      "\n",
      "training time 2.66\n",
      "Training loss: 0.070268\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9671,     0.9436\n",
      "      task_2:     0.9581,     0.9572\n",
      "      task_3:     0.9911,     0.9766\n",
      "      task_4:     0.9289,     0.9230\n",
      "\n",
      "epoch 98 validation\n",
      "\n",
      "epoch 98 val loss: 0.15726993, best val loss: 0.15681676\n",
      "patience counter is at 1 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9470,     0.9081\n",
      "      task_2:     0.9480,     0.9464\n",
      "      task_3:     0.9870,     0.9669\n",
      "      task_4:     0.8970,     0.8827\n",
      "\n",
      "epoch: 99\n",
      "\n",
      "training time 2.64\n",
      "Training loss: 0.059159\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9661,     0.9430\n",
      "      task_2:     0.9579,     0.9570\n",
      "      task_3:     0.9922,     0.9794\n",
      "      task_4:     0.9302,     0.9229\n",
      "\n",
      "epoch 99 validation\n",
      "\n",
      "epoch 99 val loss: 0.15756910, best val loss: 0.15681676\n",
      "patience counter is at 2 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9480,     0.9101\n",
      "      task_2:     0.9450,     0.9432\n",
      "      task_3:     0.9880,     0.9698\n",
      "      task_4:     0.9010,     0.8878\n",
      "\n",
      "epoch: 100\n",
      "\n",
      "training time 2.61\n",
      "Training loss: 0.064642\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9671,     0.9448\n",
      "      task_2:     0.9585,     0.9577\n",
      "      task_3:     0.9917,     0.9782\n",
      "      task_4:     0.9310,     0.9244\n",
      "\n",
      "epoch 100 validation\n",
      "\n",
      "epoch 100 val loss: 0.15668043, best val loss: 0.15681676\n",
      "patience counter is at 0 of 5\n",
      "        task:      micro        macro\n",
      "      task_1:     0.9480,     0.9099\n",
      "      task_2:     0.9470,     0.9452\n",
      "      task_3:     0.9890,     0.9722\n",
      "      task_4:     0.9000,     0.8860\n",
      "\n",
      "Model training hit max epochs, not converged\n",
      "saving to savedmodels/clc_test/clc_test_foldclc.h5\n",
      "\n",
      "Scoring train set\n",
      "\n",
      "Scoring test set\n",
      "\n",
      "Scoring val set\n",
      "\n",
      "Predicting train set\n",
      "\n",
      "Predicting test set\n",
      "\n",
      "Predicting val set\n",
      "Saving predictions to csv\n",
      "\n",
      "Evaluating train set\n",
      "\n",
      "Evaluating test set\n",
      "\n",
      "Evaluating val set\n",
      "Saving predictions to csv\n",
      "\n",
      "Full model file has been saved at savedmodels/clc_test/clc_test_20230816095553_fold0_clc_full.h5\n"
     ]
    }
   ],
   "source": [
    "run_clc.run_case_level(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98e02cb",
   "metadata": {},
   "source": [
    "Keep in mind that this example was on synthetic data, and the groupings designed for this example were artifical as well, hence the overfitting and non-convergence of the model. In real world data, this model provides an additional increase in accuracy over the base hisan or cnn, see this paper https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0232840."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

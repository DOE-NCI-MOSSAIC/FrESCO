{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d8379bc",
   "metadata": {},
   "source": [
    "This is an example for running the FrESCO library with unlabelled imdb data included within the FrESCO repository. This notebook outlines the steps in the provided script `use_model.py` for making predictions from a trained model. The data has been preprocessed and is ready for inference. If you've not already done so, go to the data directory and unzip the dataset using the command `$ tar -xf inference.tar.gz`. This script requires a model trained on the imdb dataset, so check out our imdb example notebook, if you've not already got a trained model ready to go. Lastly, move the saved model to the `notebooks/savedmodels/` directory to make running this example easier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ac61f8",
   "metadata": {},
   "source": [
    "The directory `inference/` does not have all of the required files for the vocabulary and word embeddings, only the unlabelled data we want to make predictions on. We must bring those over from the data directory from the trained model. Before copying those required files, let's check out the format of the unlabeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73e0d0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>X</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well, I have to admit that this movie brought ...</td>\n",
       "      <td>[541, 136, 22, 4, 1056, 8, 9, 19, 748, 44, 264...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The film is not for everyone. Some might think...</td>\n",
       "      <td>[0, 21, 5, 24, 15, 3808, 44, 214, 96, 0, 137, ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie is soo bad that I've wasted way to ...</td>\n",
       "      <td>[9, 19, 5, 26416, 97, 8, 3366, 1107, 111, 4, 7...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I bought a tape of this film based on the reco...</td>\n",
       "      <td>[136, 1172, 1, 2543, 3, 9, 21, 454, 18, 0, 811...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Krajobraz po bitwie like many films of Wajda i...</td>\n",
       "      <td>[159048, 159048, 159048, 34, 100, 133, 3, 1590...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>I grew up in New York City and every afternoon...</td>\n",
       "      <td>[136, 2107, 58, 6, 226, 40859, 1086, 2, 174, 4...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Very good political thriller regarding the aft...</td>\n",
       "      <td>[45, 51, 999, 1176, 2806, 0, 10380, 3, 14087, ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>J Carol Nash and Ralph Morgan star in a movie ...</td>\n",
       "      <td>[126661, 94533, 159048, 2, 159048, 135044, 568...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Although it really isn't such a terribly movie...</td>\n",
       "      <td>[433, 10, 56, 204, 138, 1, 1960, 19, 2489, 121...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Once again seeing this kind of movies turns me...</td>\n",
       "      <td>[347, 322, 310, 9, 236, 3, 125, 480, 82, 46, 2...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  \\\n",
       "0     Well, I have to admit that this movie brought ...   \n",
       "1     The film is not for everyone. Some might think...   \n",
       "2     This movie is soo bad that I've wasted way to ...   \n",
       "3     I bought a tape of this film based on the reco...   \n",
       "4     Krajobraz po bitwie like many films of Wajda i...   \n",
       "...                                                 ...   \n",
       "9995  I grew up in New York City and every afternoon...   \n",
       "9996  Very good political thriller regarding the aft...   \n",
       "9997  J Carol Nash and Ralph Morgan star in a movie ...   \n",
       "9998  Although it really isn't such a terribly movie...   \n",
       "9999  Once again seeing this kind of movies turns me...   \n",
       "\n",
       "                                                      X split  \n",
       "0     [541, 136, 22, 4, 1056, 8, 9, 19, 748, 44, 264...  test  \n",
       "1     [0, 21, 5, 24, 15, 3808, 44, 214, 96, 0, 137, ...  test  \n",
       "2     [9, 19, 5, 26416, 97, 8, 3366, 1107, 111, 4, 7...  test  \n",
       "3     [136, 1172, 1, 2543, 3, 9, 21, 454, 18, 0, 811...  test  \n",
       "4     [159048, 159048, 159048, 34, 100, 133, 3, 1590...  test  \n",
       "...                                                 ...   ...  \n",
       "9995  [136, 2107, 58, 6, 226, 40859, 1086, 2, 174, 4...  test  \n",
       "9996  [45, 51, 999, 1176, 2806, 0, 10380, 3, 14087, ...  test  \n",
       "9997  [126661, 94533, 159048, 2, 159048, 135044, 568...  test  \n",
       "9998  [433, 10, 56, 204, 138, 1, 1960, 19, 2489, 121...  test  \n",
       "9999  [347, 322, 310, 9, 236, 3, 125, 480, 82, 46, 2...  test  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "unlabeled = pd.read_csv(\"../data/inference/data_fold0.csv\")\n",
    "unlabeled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32b9b65",
   "metadata": {},
   "source": [
    "We've got three columns, the review, tokenized reviews `X`, and the split `test`. We've tokenized these with the same vocab mappings as in the trained model, so the words match up between the two datasets. Now we can copy over the other required files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9ccccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp ../data/imdb/*.json ../data/inference/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7466cac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp ../data/imdb/word_embeds_fold0.npy ../data/inference/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3ff17e",
   "metadata": {},
   "source": [
    "We'll walk through how to make predictions from a trained model, in a notebook style. This is essentially a notebook version of the script `use_model.py `, which is included for use at the command line. First we'll need some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be1268dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from fresco.validate import exceptions\n",
    "from fresco.validate import validate_params\n",
    "from fresco.data_loaders import data_utils\n",
    "from fresco.abstention import abstention\n",
    "from fresco.models import mthisan, mtcnn\n",
    "from fresco.predict import predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ee90e2",
   "metadata": {},
   "source": [
    "Now we'll setup the required function definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb736efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_dict(model_path, valid_params, data_path=\"\"):\n",
    "    \"\"\"Load pretrained model from disk.\n",
    "\n",
    "        Args:\n",
    "            model_path: str, from command line args, points to saved model\n",
    "            valid_params: ValidateParams class, with model_args dict\n",
    "            data_path: str or None, using data from the trained model, or different one\n",
    "\n",
    "        We check if the supplied path is valid and if the packages match needed\n",
    "            to run the pretrained model.\n",
    "\n",
    "    \"\"\"\n",
    "    if os.path.exists(model_path):\n",
    "        model_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    else:\n",
    "        raise exceptions.ParamError(\"Provided model path does not exist\")\n",
    "    if len(data_path) > 0:\n",
    "        with open(data_path + 'metadata.json', 'r', encoding='utf-8') as f:\n",
    "            data_args = json.load(f)\n",
    "\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Loading trained model from {model_path}\")\n",
    "    else:\n",
    "        raise exceptions.ParamError(f'the model at {model_path} does not exist.')\n",
    "\n",
    "    mismatches = []\n",
    "    # check to see if the stored package matches the expected one\n",
    "    if len(mismatches) > 0:\n",
    "        with open('metadata_package.json', 'w', encoding='utf-8') as f_out:\n",
    "            json.dump(model_dict['metadata_package'], f_out, indent=2)\n",
    "            raise exceptions.ParamError(f'the package(s) {\", \".join(mismatches)} does not match ' +\n",
    "                                        f'the generated data in {data_path}.' +\n",
    "                                         '\\nThe needed recreation info is in metadata_package.json')\n",
    "\n",
    "    return model_dict\n",
    "\n",
    "\n",
    "def load_model(model_dict, device, dw):\n",
    "\n",
    "    model_args = model_dict['metadata_package']['mod_args']\n",
    "\n",
    "    if model_args['model_type'] == 'mthisan':\n",
    "        model = mthisan.MTHiSAN(dw.inference_data['word_embedding'],\n",
    "                                dw.num_classes,\n",
    "                                **model_args['MTHiSAN_kwargs'])\n",
    "\n",
    "    elif model_args['model_type'] == 'mtcnn':\n",
    "        model = mtcnn.MTCNN(dw.inference_data['word_embedding'],\n",
    "                            dw.num_classes,\n",
    "                            **model_args['MTCNN_kwargs'])\n",
    "\n",
    "    model.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    model_dict = {k: v for k,v in model_dict.items() if k!='metadata_package'}\n",
    "    # model_dict = {k.replace('module.',''): v for k,v in model_dict.items()}\n",
    "    model.load_state_dict(model_dict)\n",
    "\n",
    "    print('model loaded')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e318284c",
   "metadata": {},
   "source": [
    "The FrESCO library is typically run from the command line with arguments specifying the model type and model args, so we'll have to set them up manually for this notebook. If you're wanting to run the script from the commandline the command is: `$python use_model.py -mp /path/to/model -dp /path/to/data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48aeebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    _ = parser.add_argument('--model_path', '-mp', type=str, default='',\n",
    "                            help=\"\"\"this is the location of the model\n",
    "                                that will used to make predictions\"\"\")\n",
    "    _ = parser.add_argument('--data_path', '-dp', type=str, default='',\n",
    "                            help=\"\"\"where the data will load from. The default is\n",
    "                                    the path saved in the model\"\"\")\n",
    "    _ = parser.add_argument('--model_args', '-args', type=str, default='',\n",
    "                            help=\"\"\"path to specify the model_args; default is in\n",
    "                                    the configs/ directory\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea87a00",
   "metadata": {},
   "source": [
    "We are going to make predictions on an unlabelled dataset, so we'll specify an information extraction model and point to the unlabelled dataset directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaf88369",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(args=['-mp', 'savedmodels/model/model.h5', '-dp', '../data/inference'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b227b67c",
   "metadata": {},
   "source": [
    "Next, we need to verfiy the `model_args` are sane and load the saved model from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37644971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating kwargs in model_args.yml file\n",
      "Loading trained model from savedmodels/model/model.h5\n",
      "Validating kwargs from pretrained model \n"
     ]
    }
   ],
   "source": [
    "    # 1. validate model/data args\n",
    "    print(\"Validating kwargs in model_args.yml file\")\n",
    "    data_source = 'pre-generated'\n",
    "    # use the model args file from training\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_dict = load_model_dict(args.model_path, device)\n",
    "    mod_args = model_dict['metadata_package']['mod_args']\n",
    "\n",
    "    print(\"Validating kwargs from pretrained model \")\n",
    "    model_args = validate_params.ValidateParams(args,\n",
    "                                                data_source=data_source,\n",
    "                                                model_args=mod_args)\n",
    "\n",
    "    model_args.check_data_train_args(from_pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086d2541",
   "metadata": {},
   "source": [
    "We'll define a model architecture, set up abstention if the saved model was trained with it enabled, and check that the required data files exits. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d664a573",
   "metadata": {},
   "outputs": [],
   "source": [
    "    if model_args.model_args['model_type'] == 'mthisan':\n",
    "        model_args.hisan_arg_check()\n",
    "    elif model_args.model_args['model_type'] == 'mtcnn':\n",
    "        model_args.mtcnn_arg_check()\n",
    "\n",
    "    if model_args.model_args['abstain_kwargs']['abstain_flag']:\n",
    "        model_args.check_abstain_args()\n",
    "\n",
    "    model_args.check_data_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09c4b80",
   "metadata": {},
   "source": [
    "Great, we can set the random number seeds next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97b7d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    if model_args.model_args['data_kwargs']['reproducible']:\n",
    "        seed = model_args.model_args['data_kwargs']['random_seed']\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "    else:\n",
    "        seed = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8746c345",
   "metadata": {},
   "source": [
    "Let's go ahead and load the data. We'll also create the inference loader for our dataset needed to feed data to the gpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7eff98d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ../data/inference\n",
      "Num workers: 4, reproducible: True\n"
     ]
    }
   ],
   "source": [
    "    dw = data_utils.DataHandler(data_source, model_args.model_args)\n",
    "    dw.load_folds(fold=0)\n",
    "\n",
    "    data_loader = dw.inference_loader(reproducible=model_args.model_args['data_kwargs']['reproducible'],\n",
    "                                      seed=seed,\n",
    "                                      batch_size=model_args.model_args['train_kwargs']['batch_per_gpu'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a35690",
   "metadata": {},
   "source": [
    "Now we're ready to load a model and create the class to predict on our unlabeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "043f2324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "    model = load_model(model_dict, device, dw)\n",
    "\n",
    "    # Make predictions from pretrained model\n",
    "    evaluator = predictions.ScoreModel(model_args.model_args, data_loader, model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d475bb",
   "metadata": {},
   "source": [
    "And we can make the predictions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "457d3e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting test set\n",
      "Saving predictions to csv\n"
     ]
    }
   ],
   "source": [
    "    evaluator.predict(dw.dict_maps['id2label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a6ac47",
   "metadata": {},
   "source": [
    "The predictions on the unlabelled data is saved in the `predictions` folder with the name specified in the `model_args` file and a time stamp to prevent name-clashes and overwriting data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
